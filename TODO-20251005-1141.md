# NTT Status & Challenges - 2025-10-05 11:41

## ✅ Completed This Session

### 1. Adaptive query fix
- **Location**: `ntt-copier.py:326-403` (`fetch_and_claim_work_unit()`)
- **Problem**: Code documented adaptive logic but always used TABLESAMPLE, even for 2-item queues
- **Solution**: Implemented missing conditional logic
  - Small queues (≤5000): Direct `ORDER BY RANDOM()` query (~1ms)
  - Large queues (>5000): TABLESAMPLE query
- **Result**: 75x performance improvement (70-80ms → <1ms for small queues)
- **Status**: Tested on floppy disk, working correctly

### 2. Error handling for persistent failures
- **Location**: `ntt-copier.py:439-484` (`release_claim()`)
- **Problem**: Workers infinitely retried failed items (ino=1 claimed 17 times in 40ms)
- **Solution**:
  - Track errors in `inode.errors` array
  - After 3 consecutive identical errors, auto-mark as EXCLUDED
  - Added logging to confirm `release_claim()` execution
  - Extended `mark_inode_excluded()` to accept reason parameter
- **Result**: No more infinite loops, failed items properly excluded
- **Status**: Tested successfully, ino=1 correctly excluded after 3 failures

### 3. Bytes/str conversion fix
- **Location**: `ntt-copier.py:868-890` (`execute_directory_fs()`, `execute_symlink_fs()`)
- **Problem**: TypeError "a bytes-like object is required, not 'str'" when processing directories
- **Root cause**: Paths stored as bytea in database, returned as Python bytes, but Path() expects str
- **Solution**: Added `.decode('utf-8', errors='replace')` before using with Path objects
- **Result**: Directory and symlink processing now works correctly
- **Status**: Tested successfully, ino=1 (root directory) processes without errors

## 🔄 Current State

### Media Status
- **Floppy disk (eba88f0c)**: 34 of 35 files copied successfully, ino=1 (root dir) now works
- **bb22 (bb226d2a)**: Loader still running in background
- **Total media**: 13 media, 122M+ paths across all media

### Database Schema
- **Path storage**: All paths confirmed as bytea (no mix of text/bytea)
  - PostgreSQL auto-converts text literals to bytea on insert
  - Substring search works: `convert_from(path, 'UTF8') LIKE '%pattern%'`
- **Inode errors**: `errors` column (text[]) tracks failure history

### Performance
- Queue depth: Varies by medium (adaptive query adjusts automatically)
- Worker claims: <1ms on small queues (was 70-80ms)
- Error tracking: Properly logs and excludes after 3 identical failures

## ⚠️ Pending Challenges

### 1. Image mounting capability (HIGH PRIORITY)
**Problem**: Workers require manual mounting before processing
```bash
# Current workaround (manual)
sudo losetup -f --show -r /data/fast/img/{image_hash}.img
sudo mount -t vfat -o ro,noatime,nodev,nosuid,fmask=0022,dmask=0022 /dev/loop0 /mnt/ntt/{medium_hash}
```

**Options**:
- A) Workers auto-mount on first access (complex, requires sudo)
- B) Orchestrator mounts after enumeration (simpler, centralized)
- C) Separate mount daemon that watches for new media

**Impact**: Without this, floppies and other image-based media require manual intervention

### 2. Schema evolution - fs_type column
**Blocker**: Waiting for bb22 loader to finish before altering schema

**Required changes**:
- Add `fs_type` column to `medium` table (e.g., 'vfat', 'hfsplus', 'ext4')
- Update `ntt-orchestrator` to detect and persist fs_type during imaging
- Update `ntt-copier` to use medium.fs_type instead of detecting per-file

**Impact**: Currently detecting fs_type per-inode is inefficient

### 3. Uncommitted changes - testing needed
**Files modified**:
- `bin/ntt-copier.py` (adaptive query, error handling, bytes/str fixes)
- `bin/ntt-imager` (sector counting, tiered exit strategy)
- `bin/ntt-loader` (bytea conversion - not yet committed)
- `bin/ntt-orchestrator` (timestamp naming, early medium insert)

**Testing needed**:
- Full worker runs on bb22 (large media, millions of files)
- Verify adaptive query threshold (5000) is optimal
- Ensure error handling doesn't create false positives

**Can't commit until**: Verified on production workload

## 📊 Key Metrics

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Claim time (small queue) | 70-80ms | <1ms | 75x faster |
| Claim hit rate (small queue) | ~5% | ~100% | Reliable |
| Error loop prevention | None | 3-strike auto-exclude | No infinite loops |

## ❓ Open Questions

1. **Adaptive query threshold**: Keep 5000 or adjust after bb22 testing?
2. **Image mounting**: Who mounts? Workers, orchestrator, or separate daemon?
3. **Error backoff**: Need exponential backoff in addition to 3-strike rule?
4. **Mount permissions**: How to handle sudo requirements for mounting?
5. **fs_type detection**: Should orchestrator detect at imaging time or enumeration time?

## 🎯 Next Steps

1. Wait for bb22 loader to finish
2. Test adaptive query on bb22 workload (large queue behavior)
3. Decide on mounting strategy and implement
4. Add fs_type column to medium table
5. Update orchestrator to persist fs_type
6. Full testing cycle on production data
7. Commit changes with proper documentation

## 🐛 Known Issues

- **Permission errors**: Image mounts owned by root, workers run as user
  - Workaround: Use sudo for copier, or fix mount permissions
- **Hardcoded paths**: Mount point paths include full `/mnt/ntt/{medium_hash}/` prefix
  - May need path normalization for archive storage
- **No image cleanup**: Loop devices and mounts persist after worker completion
  - Need cleanup strategy (orchestrator? worker? cron?)
