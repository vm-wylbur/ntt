#!/usr/bin/env bash
# Author: PB and Claude
# Date: Sun 13 Oct 2025
# License: (c) HRDAG, 2025, GPL-2 or newer
#
# ------
# ntt/bin/ntt-enum-carved
#
# Enumerate PhotoRec carved files with synthetic metadata for NTT pipeline
# Generates .raw format compatible with ntt-loader
#
# PHYSICAL ORGANIZATION:
#   PhotoRec outputs carved.N/ or recup_dir.N/ directories (both patterns supported)
#   Organize under /data/cold/carved-sources/${SOURCE}/ for movable files
#   Create symlink: /mnt/ntt/${MEDIUM_HASH} -> physical location
#
# SETUP EXAMPLE (movable files):
#   # Organize files (handles both carved.* and recup_dir.*)
#   mkdir -p /data/cold/carved-sources/sda-20251013
#   mv /data/cold/carved.* /data/cold/recup_dir.* /data/cold/carved-sources/sda-20251013/ 2>/dev/null || true
#
#   # Create symlink
#   mkdir -p /mnt/ntt
#   ln -s /data/cold/carved-sources/sda-20251013 /mnt/ntt/carved-sda-20251013
#
# SETUP EXAMPLE (immovable files):
#   # Create symlink to immovable source
#   mkdir -p /mnt/ntt
#   ln -s /immovable/photorec/output /mnt/ntt/carved-hdd2-20251020
#
# USAGE:
#   ./ntt-enum-carved /data/cold/carved-sources/sda-20251013 carved-sda-20251013 output.raw
#
# OUTPUT PATHS:
#   Database paths preserve directory type and include source identifier:
#     carved-sda-20251013/carved.1/filename
#     carved-sda-20251013/recup_dir.123/filename
#   This allows querying carved files without medium_hash context
#   Copier uses: --src-root /mnt/ntt (consistent across all carved sources)
#
# SEE ALSO:
#   docs/carved-ingestion-workflow.md - Full workflow documentation
#
set -euo pipefail

# ---------- argparse ----------
usage() {
  echo "Usage: $0 CARVED_ROOT MEDIUM_HASH OUT.raw"
  echo ""
  echo "Example:"
  echo "  $0 /data/cold/carved carved-sda-20251013 /data/fast/raw/carved-sda.raw"
  echo ""
  echo "Enumerates carved.* and recup_dir.* subdirectories under CARVED_ROOT"
  exit 1
}
[[ $# -eq 3 ]] || usage
CARVED_ROOT="$1"; MEDIUM_HASH="$2"; OUT="$3"

# ---------- env / config ----------
LOG_JSON="${NTT_ENUM_LOG:-/var/log/ntt/enum.jsonl}"
mkdir -p "$(dirname "$LOG_JSON")"
mkdir -p "$(dirname "$OUT")"
chmod 755 "$(dirname "$LOG_JSON")" 2>/dev/null || true
chmod 755 "$(dirname "$OUT")" 2>/dev/null || true

# ---------- JSON helper ----------
log() {
  jq -cn --arg ts "$(date -Iseconds)" \
        --arg stage "$1" \
        --argjson extra "$2" \
  >> "$LOG_JSON"
}

# ---------- sanity checks ----------
if [[ ! -d "$CARVED_ROOT" ]]; then
  log error "{\"msg\": \"carved root not found\", \"root\": \"$CARVED_ROOT\"}"
  echo "Error: Carved root directory not found: $CARVED_ROOT" >&2
  exit 1
fi

# Check for carved.* and recup_dir.* subdirectories
CARVED_DIRS=$(find "$CARVED_ROOT" -maxdepth 1 -type d \( -name 'carved.*' -o -name 'recup_dir.*' \) | sort -V)
if [[ -z "$CARVED_DIRS" ]]; then
  log error "{\"msg\": \"no carved.* or recup_dir.* subdirectories found\", \"root\": \"$CARVED_ROOT\"}"
  echo "Error: No carved.* or recup_dir.* subdirectories found in $CARVED_ROOT" >&2
  exit 1
fi

DIR_COUNT=$(echo "$CARVED_DIRS" | wc -l)
CARVED_COUNT=$(echo "$CARVED_DIRS" | grep -c 'carved\.' || true)
RECUP_COUNT=$(echo "$CARVED_DIRS" | grep -c 'recup_dir\.' || true)
echo "[$(date -Iseconds)] Found $DIR_COUNT PhotoRec directories ($CARVED_COUNT carved.*, $RECUP_COUNT recup_dir.*)" >&2

# ---------- enumerate ----------
log start "{\"root\": \"$CARVED_ROOT\", \"medium_hash\": \"$MEDIUM_HASH\", \"out\": \"$OUT\", \"dir_count\": $DIR_COUNT}"

# Temporary file for building output
TMP_OUT="${OUT}.tmp.$$"
trap "rm -f '$TMP_OUT'" EXIT

TOTAL_FILES=0

# Global sequential inode counter (all files get unique ino across all directories)
INO=1

# Enumerate each PhotoRec directory (carved.* or recup_dir.*)
while IFS= read -r CARVED_DIR; do
  # Get directory basename
  DIR_BASENAME=$(basename "$CARVED_DIR")

  echo "[$(date -Iseconds)] Processing $DIR_BASENAME..." >&2

  # Find all files in this directory
  while IFS= read -r FILE; do
    # Get file size and mtime
    SIZE=$(stat -c '%s' "$FILE" 2>/dev/null || echo "0")
    MTIME=$(stat -c '%Y' "$FILE" 2>/dev/null || echo "0")

    # Construct relative path: medium_hash/DIR_BASENAME/filename
    # Preserves original directory type (carved.N or recup_dir.N)
    # This makes paths self-documenting and distinguishes multiple carved sources
    REL_PATH="${MEDIUM_HASH}/${DIR_BASENAME}/$(basename "$FILE")"

    # Output format: fs_type, dev, ino, nlink, size, mtime, path
    # fs_type='f' (regular file), dev=1 (constant), ino=sequential across all files, nlink=1
    printf 'f\034%s\034%s\034%s\034%s\034%s\034%s\0' \
      "1" "$INO" "1" "$SIZE" "$MTIME" "$REL_PATH" >> "$TMP_OUT"

    INO=$((INO + 1))
    TOTAL_FILES=$((TOTAL_FILES + 1))

    # Progress every 1000 files
    if ((TOTAL_FILES % 1000 == 0)); then
      echo "[$(date -Iseconds)] Processed $TOTAL_FILES files..." >&2
    fi
  done < <(find "$CARVED_DIR" -maxdepth 1 -type f ! -name '*.log' ! -name '*.ses' -print0 | tr '\0' '\n')

done <<< "$CARVED_DIRS"

# Move temp file to final output
mv "$TMP_OUT" "$OUT"
chmod 644 "$OUT" 2>/dev/null || true

echo "[$(date -Iseconds)] âœ“ Enumeration complete: $TOTAL_FILES files from $DIR_COUNT directories" >&2
log enum_complete "{\"rows\": $TOTAL_FILES, \"out\": \"$OUT\", \"dir_count\": $DIR_COUNT}"
log done "{\"rows\": $TOTAL_FILES, \"exit\": 0}"

chmod 644 "$LOG_JSON" 2>/dev/null || true
exit 0
