#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "textual>=0.45.0",
#     "plotext>=5.0.0",
#     "textual-plotext>=0.2.0",
#     "psycopg[binary]>=3.0.0",
#     "rich>=13.0.0"
# ]
# ///
#
# Author: PB and Claude
# Date: 2025-09-28
# License: (c) HRDAG, 2025, GPL-2 or newer
#
# ------
# ntt/bin/ntt-dashboard
#
# NTT System Dashboard - Real-time monitoring TUI for NTT tools
#
# Features:
# - Tool-specific monitoring tabs (Copier, Re-Hardlink, Verify)
# - Shared system stats across all tabs
# - Live worker status monitoring (no sudo required)
# - Database metrics and queue depth tracking
# - Processing throughput charts
#
# Requirements:
#   - Python 3.13+
#   - PostgreSQL access (same credentials as ntt-copier)
#   - Read access to worker PID files and logs

import asyncio
import os
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, NamedTuple

import plotext as plt
from textual_plotext import PlotextPlot
import psycopg
from psycopg.rows import dict_row
from rich.text import Text
from textual.app import App, ComposeResult
from textual.containers import Grid, Horizontal, Vertical
from textual.widgets import (
    DataTable, Footer, Header, Label, Log,
    TabbedContent, TabPane, Static, Sparkline
)
from textual.reactive import reactive
from textual.timer import Timer


# Configuration - same as ntt-copier.py for consistency
DB_URL = os.environ.get('NTT_DB_URL', 'postgresql:///copyjob')
PID_FILE = Path('/tmp/ntt-workers.pids')
WORKER_LOG_PATTERN = '/tmp/ntt-worker-*.log'
VERIFY_LOG = Path(os.environ.get('NTT_LOG_JSON', '/var/log/ntt/verify.jsonl'))

# Set PostgreSQL user to original user when running under sudo
if 'SUDO_USER' in os.environ:
    os.environ['PGUSER'] = os.environ['SUDO_USER']
elif os.geteuid() == 0 and 'USER' in os.environ:
    os.environ['PGUSER'] = 'postgres'

# If running as root and DB_URL doesn't specify a user, add the original user
if os.geteuid() == 0 and 'SUDO_USER' in os.environ:
    if '://' in DB_URL and '@' not in DB_URL:
        DB_URL = DB_URL.replace(':///', f"://{os.environ['SUDO_USER']}@localhost/")


class WorkerStatus(NamedTuple):
    """Immutable worker status data for caching and display."""
    pid: int
    worker_id: str
    status: str  # 'running', 'stopped', 'error'
    uptime: str
    cpu_percent: float = 0.0


class SystemMetrics(NamedTuple):
    """Immutable system metrics for dashboard display."""
    queue_depth: int
    files_processed_today: int
    total_files_processed: int
    processing_rate: float  # files per second
    dedup_ratio: float  # percentage
    last_updated: datetime


class SystemStatsPanel(Static):
    """Reusable system stats panel that updates globally."""

    def compose(self) -> ComposeResult:
        """Create the system stats display."""
        with Horizontal(id="system-stats-row"):
            yield Label("CPU: --", id="cpu-compact")
            yield Label("Load: --", id="load-compact")
            yield Label("Temp: --", id="temp-compact")
            yield Label("IO: --", id="io-compact")
            yield Label("Mem: --", id="mem-compact")
            yield Label("Pressure: --", id="pressure-compact")

    def update_stats(self, cpu: float, load: float, temp: float, iowait: float, mem: float, pressure: float):
        """Update all system stats displays."""
        # Update CPU
        cpu_label = self.query_one("#cpu-compact", Label)
        cpu_label.update(f"CPU: {cpu:.1f}%")
        if cpu > 80:
            cpu_label.styles.color = "red"
        elif cpu > 60:
            cpu_label.styles.color = "yellow"
        else:
            cpu_label.styles.color = "green"

        # Update Load Average
        load_label = self.query_one("#load-compact", Label)
        load_label.update(f"Load: {load:.1f}")
        # Color based on CPU count (assume reasonable load = CPU count)
        import os
        cpu_count = os.cpu_count() or 8
        if load > cpu_count * 1.5:
            load_label.styles.color = "red"
        elif load > cpu_count:
            load_label.styles.color = "yellow"
        else:
            load_label.styles.color = "green"

        # Update Temperature
        temp_label = self.query_one("#temp-compact", Label)
        if temp > 0:
            temp_label.update(f"Temp: {temp:.0f}°C")
            if temp > 85:
                temp_label.styles.color = "red"
            elif temp > 70:
                temp_label.styles.color = "yellow"
            else:
                temp_label.styles.color = "green"
        else:
            temp_label.update("Temp: N/A")
            temp_label.styles.color = "dim"

        # Update IOwait
        io_label = self.query_one("#io-compact", Label)
        io_label.update(f"IO: {iowait:.1f}%")
        if iowait > 30:
            io_label.styles.color = "red"
        elif iowait > 10:
            io_label.styles.color = "yellow"
        else:
            io_label.styles.color = "green"

        # Update Memory
        mem_label = self.query_one("#mem-compact", Label)
        mem_label.update(f"Mem: {mem:.1f}%")
        if mem > 90:
            mem_label.styles.color = "red"
        elif mem > 80:
            mem_label.styles.color = "yellow"
        else:
            mem_label.styles.color = "green"

        # Update Pressure
        pressure_label = self.query_one("#pressure-compact", Label)
        pressure_label.update(f"Pressure: {pressure:.0f}%")
        if pressure >= 80:
            pressure_label.styles.color = "red"
        elif pressure >= 60:
            pressure_label.styles.color = "yellow"
        else:
            pressure_label.styles.color = "green"


class ThroughputGraph(PlotextPlot):
    """Live updating throughput graph using textual-plotext"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.rate_history = []

    def update_data(self, history: list[tuple[float, float]]):
        """Update with new rate history data"""
        self.rate_history = history
        self.update_plot()

    def on_mount(self) -> None:
        """Called when widget is mounted"""
        self.update_plot()

    def update_plot(self) -> None:
        """Update the plot with current data"""
        if not self.rate_history:
            self.plt.text("Waiting for data...", x=0, y=0)
            self.refresh()
            return

        # Configuration
        WINDOW_SIZE = 20  # Always show 20 positions
        recent = self.rate_history[-WINDOW_SIZE:]

        # Prepare data
        rates = [r for _, r in recent]
        num_points = len(rates)

        # X positions: right-align so newest data is always at position 19
        x_offset = WINDOW_SIZE - num_points
        x_positions = list(range(x_offset, WINDOW_SIZE))

        # Clear and configure
        self.plt.clear_figure()

        # Create bars
        self.plt.bar(x_positions, rates)

        # Fixed X-axis range (always 0-19)
        self.plt.xlim(0, WINDOW_SIZE - 1)

        # X-axis labels: relative time (leftmost = -100s, rightmost = now)
        x_labels = [f"-{(WINDOW_SIZE - i - 1) * 5}s" if i % 5 == 0 else "" for i in range(WINDOW_SIZE)]
        x_labels[-1] = "now"  # Rightmost is "now"
        self.plt.xticks(list(range(WINDOW_SIZE)), x_labels)

        # Fixed Y-axis: 0 to 10000 with 3 labels only
        self.plt.ylim(0, 10000)
        self.plt.yticks([0, 5000, 10000], ["0", "5000", "10000"])
        self.plt.yfrequency(0)  # Disable auto ticks

        # Styling (no title for more vertical space)
        self.plt.xlabel("Time (5s intervals)")
        self.plt.ylabel("inodes/sec")

        # Trigger refresh to display
        self.refresh()


class ExponentialMovingAverage:
    """Exponential moving average for smoothing rate calculations."""
    def __init__(self, alpha=0.3):
        """
        alpha: smoothing factor (0-1)
        - Higher alpha = more weight on recent values
        - Lower alpha = smoother, more historical weight
        - Common: 0.1-0.3 for smoothing
        """
        self.alpha = alpha
        self.ema = None

    def add(self, value):
        if self.ema is None:
            self.ema = value
        else:
            self.ema = self.alpha * value + (1 - self.alpha) * self.ema
        return self.ema


class NTTDashboard(App):
    """Main TUI application for NTT system monitoring."""

    CSS = """
    #system-stats-row {
        height: 3;
        background: $surface;
        padding: 1;
        margin-bottom: 1;
    }

    #system-stats-row Label {
        width: 1fr;
        text-align: center;
    }

    .status-running {
        color: green;
    }
    .status-stopped {
        color: red;
    }
    .status-error {
        color: yellow;
    }
    .status-done {
        color: cyan;
    }
    .status-unknown {
        color: orange;
    }

    .metric-good {
        color: green;
    }
    .metric-warning {
        color: yellow;
    }
    .metric-critical {
        color: red;
    }

    .panel-title {
        background: $primary;
        color: $text;
        text-style: bold;
        padding: 1;
        width: 100%;
        text-align: center;
    }

    .metrics-container {
        padding: 1;
    }

    DataTable {
        height: 100%;
    }

    #copier-rate-graph {
        height: 18;
        border: solid $primary;
    }
    """

    # Reactive attributes for live updates
    worker_count = reactive(0)
    queue_depth = reactive(0)
    processing_rate = reactive(0.0)

    def __init__(self):
        super().__init__()
        self.db_conn: Optional[psycopg.Connection] = None
        self.update_timer: Optional[Timer] = None
        self.worker_data: List[WorkerStatus] = []
        self.metrics_history: List[SystemMetrics] = []
        self.current_cpu_load: float = 0.0
        self.current_iowait: float = 0.0
        self.current_cpu_temp: float = 0.0
        self.current_mem_usage: float = 0.0
        self.current_mem_pressure: float = 0.0
        self.inode_dedup_ratio: float = 0.0
        self.hardlink_stats = None
        self.prev_hardlink_stats = None
        self.hardlink_stats_time = None
        self.hardlink_blob_rate: float = 0.0
        self.hardlink_link_rate: float = 0.0
        self.verify_stats = None
        self.system_stats_panels: List[SystemStatsPanel] = []

        # Track processing rate with delta calculation
        self.prev_processed_count: int = 0
        self.prev_processed_time: float = 0.0
        self.processing_rate_ema = ExponentialMovingAverage(alpha=0.2)

        # Track rate history for max calculations (timestamp, rate)
        self.rate_history: List[tuple[float, float]] = []

    def compose(self) -> ComposeResult:
        """Create the main UI layout with tool-specific tabs."""
        yield Header()
        yield Footer()

        with TabbedContent(initial="copier"):
            # Copier Tab
            with TabPane("Copier", id="copier"):
                with Vertical():
                    stats_panel = SystemStatsPanel(id="copier-system-stats")
                    self.system_stats_panels.append(stats_panel)
                    yield stats_panel

                    with Grid(id="copier-grid"):
                        # Metrics Panel (includes worker status)
                        with Vertical(id="copier-metrics"):
                            yield Static("Metrics", classes="panel-title")
                            with Vertical(classes="metrics-container"):
                                yield Label("Workers: --", id="copier-worker-summary")
                                yield Label("Queue Depth: --", id="copier-queue")
                                yield Label("Processing: --", id="copier-rate")
                                yield Label("Today: --", id="copier-today")
                                yield Label("Total: --", id="copier-total")
                                yield Label("ETA: --", id="copier-eta")
                                yield Label("Dedup: --", id="copier-dedup")

                        # Graph Panel
                        with Vertical(id="copier-graph-panel"):
                            yield ThroughputGraph(id="copier-rate-graph")

            # Re-Hardlink Tab
            with TabPane("Re-Hardlink", id="hardlink"):
                with Vertical():
                    stats_panel = SystemStatsPanel(id="hardlink-system-stats")
                    self.system_stats_panels.append(stats_panel)
                    yield stats_panel

                    with Grid(id="hardlink-grid"):
                        # Progress Panel
                        with Vertical(id="hardlink-progress"):
                            yield Static("Re-Hardlink Progress", classes="panel-title")
                            with Vertical(classes="metrics-container"):
                                yield Label("Total Blobs: --", id="hl-total")
                                yield Label("Complete: --", id="hl-complete")
                                yield Label("Incomplete: --", id="hl-incomplete")
                                yield Label("Progress: --", id="hl-progress")
                                yield Label("Links: --", id="hl-links")

                        # Rates Panel
                        with Vertical(id="hardlink-rates"):
                            yield Static("Processing Rates", classes="panel-title")
                            with Vertical(classes="metrics-container"):
                                yield Label("Blob Rate: --", id="hl-blob-rate")
                                yield Label("Link Rate: --", id="hl-link-rate")
                                yield Label("Est. Time: --", id="hl-eta")

            # Verify Tab
            with TabPane("Verify", id="verify"):
                with Vertical():
                    stats_panel = SystemStatsPanel(id="verify-system-stats")
                    self.system_stats_panels.append(stats_panel)
                    yield stats_panel

                    with Grid(id="verify-grid"):
                        # Verify Status Panel
                        with Vertical(id="verify-status"):
                            yield Static("Verify Status", classes="panel-title")
                            with Vertical(classes="metrics-container"):
                                yield Label("Status: --", id="verify-status-label")
                                yield Label("Verified: --", id="verify-count")
                                yield Label("Errors: --", id="verify-errors")
                                yield Label("Rate: --", id="verify-rate")
                                yield Label("Last Check: --", id="verify-last")

                        # Verify Log Panel
                        with Vertical(id="verify-log"):
                            yield Static("Recent Activity", classes="panel-title")
                            yield Log(id="verify-log-view", max_lines=20)

    async def on_mount(self) -> None:
        """Initialize dashboard on startup."""
        self.title = "NTT Dashboard"

        # Connect to database
        try:
            await self.connect_database()
            self.notify("Connected to NTT database", severity="information")
        except Exception as e:
            self.notify(f"Database connection failed: {e}", severity="error")

        # Start periodic updates (slower to avoid CPU overload)
        self.update_timer = self.set_interval(5.0, self.update_data)

        # Initial data load
        await self.update_data()

    async def connect_database(self) -> None:
        """Establish database connection."""
        loop = asyncio.get_event_loop()
        self.db_conn = await loop.run_in_executor(
            None, lambda: psycopg.connect(DB_URL, row_factory=dict_row)
        )

    async def update_data(self) -> None:
        """Update all dashboard data."""
        try:
            # Add a small delay to prevent tight loops
            await asyncio.sleep(0.1)

            # Update system stats (shared across all tabs)
            cpu_load, iowait = await self.get_cpu_stats()
            self.current_cpu_load = cpu_load
            self.current_iowait = iowait

            load_avg = await self.get_load_average()

            self.current_cpu_temp = await self.get_cpu_temperature()

            mem_usage, mem_pressure = await self.get_memory_stats()
            self.current_mem_usage = mem_usage
            self.current_mem_pressure = mem_pressure

            # Update all system stats panels
            for panel in self.system_stats_panels:
                panel.update_stats(
                    self.current_cpu_load,
                    load_avg,
                    self.current_cpu_temp,
                    self.current_iowait,
                    self.current_mem_usage,
                    self.current_mem_pressure
                )

            # Update tool-specific data
            await self.update_worker_status()
            await self.update_verify_status()

            if self.db_conn:
                await self.update_system_metrics()

            # Refresh tool-specific displays
            self.refresh_copier_display()
            self.refresh_hardlink_display()
            self.refresh_verify_display()

        except Exception as e:
            self.notify(f"Update error: {e}", severity="warning")

    async def update_worker_status(self) -> None:
        """Read worker PIDs and check their status."""
        worker_data = []

        if not PID_FILE.exists():
            self.worker_data = []
            return

        try:
            with open(PID_FILE) as f:
                pids = [line.strip() for line in f if line.strip()]

            for i, pid_str in enumerate(pids):
                if not pid_str:
                    continue

                try:
                    pid = int(pid_str)
                    worker_id = f"worker-{i+1:02d}"

                    # Check if process is running
                    status = await self.check_process_status(pid)

                    # Find actual Python worker PID (sudo wrapper → python)
                    python_pid = await self.find_python_worker_pid(pid)

                    # Get CPU% from Python process if found
                    cpu_percent = 0.0
                    if python_pid and status == 'running':
                        cpu_percent = await self.get_process_cpu(python_pid)

                    # Check completion status from log
                    _, _, is_completed = await self.parse_worker_log(worker_id)

                    # Mark as 'done' if process is stopped AND work completed
                    if status == 'stopped' and is_completed:
                        status = 'done'

                    uptime = await self.get_process_uptime(pid)

                    worker_data.append(WorkerStatus(
                        pid=pid,
                        worker_id=worker_id,
                        status=status,
                        uptime=uptime,
                        cpu_percent=cpu_percent
                    ))

                except ValueError:
                    continue

            self.worker_data = worker_data
            self.worker_count = len([w for w in worker_data if w.status == 'running'])

        except Exception as e:
            self.notify(f"Worker status error: {e}", severity="warning")

    async def check_process_status(self, pid: int) -> str:
        """Check if a process is running using efficient OS signal."""
        try:
            os.kill(pid, 0)  # Signal 0 = check existence
            return 'running'
        except ProcessLookupError:
            return 'stopped'
        except PermissionError:
            # Permission denied means process exists but owned by another user (root)
            # This is expected for sudo-launched workers
            return 'running'
        except (OSError, ValueError):
            return 'error'

    async def get_process_uptime(self, pid: int) -> str:
        """Get process uptime string."""
        try:
            import subprocess
            loop = asyncio.get_event_loop()

            def get_uptime():
                result = subprocess.run(
                    ['ps', '-p', str(pid), '-o', 'etime='],
                    capture_output=True, text=True
                )
                if result.returncode == 0:
                    return result.stdout.strip()
                return "Unknown"

            return await loop.run_in_executor(None, get_uptime)
        except Exception:
            return "Error"

    async def find_python_worker_pid(self, sudo_pid: int) -> Optional[int]:
        """Find the actual Python worker PID by traversing children of sudo process."""
        try:
            import subprocess
            loop = asyncio.get_event_loop()

            def find_python():
                def search_descendants(pid: int, depth: int = 0) -> Optional[int]:
                    """Recursively search process tree for Python process."""
                    if depth > 5:  # Prevent infinite loops
                        return None

                    # Get children of this PID
                    result = subprocess.run(
                        ['pgrep', '-P', str(pid)],
                        capture_output=True, text=True
                    )

                    if result.returncode != 0:
                        return None

                    # Check each child
                    for child_pid_str in result.stdout.strip().split('\n'):
                        if not child_pid_str:
                            continue

                        child_pid = int(child_pid_str)

                        # Check if this is the Python process
                        cmd_result = subprocess.run(
                            ['ps', '-p', str(child_pid), '-o', 'comm='],
                            capture_output=True, text=True
                        )

                        if cmd_result.returncode == 0 and 'python' in cmd_result.stdout.lower():
                            return child_pid

                        # Recursively search this child's descendants
                        python_pid = search_descendants(child_pid, depth + 1)
                        if python_pid:
                            return python_pid

                    return None

                return search_descendants(sudo_pid)

            return await loop.run_in_executor(None, find_python)
        except Exception:
            return None

    async def get_process_cpu(self, pid: int) -> float:
        """Get CPU percentage for a process."""
        try:
            import subprocess
            loop = asyncio.get_event_loop()

            def get_cpu():
                result = subprocess.run(
                    ['ps', '-p', str(pid), '-o', '%cpu='],
                    capture_output=True, text=True
                )
                if result.returncode == 0:
                    try:
                        return float(result.stdout.strip())
                    except ValueError:
                        return 0.0
                return 0.0

            return await loop.run_in_executor(None, get_cpu)
        except Exception:
            return 0.0

    async def parse_worker_log(self, worker_id: str) -> tuple[int, float, bool]:
        """Parse worker log file to extract files processed, current rate, and completion status."""
        try:
            import re
            log_file = Path(f"/tmp/ntt-{worker_id}.log")

            if not log_file.exists():
                return 0, 0.0, False

            loop = asyncio.get_event_loop()

            def parse_log():
                try:
                    with open(log_file, 'r') as f:
                        lines = f.readlines()

                    recent_lines = lines[-30:] if len(lines) > 30 else lines

                    files_processed = 0
                    current_rate = 0.0
                    is_completed = False

                    # Check for completion
                    for line in recent_lines:
                        if any(phrase in line.lower() for phrase in [
                            'worker complete',
                            'completed successfully',
                            'finished processing',
                            'all files processed',
                            'worker exiting',
                            'shutting down gracefully',
                            'work complete',
                            'worker.*finished'
                        ]):
                            is_completed = True

                    # Extract latest heartbeat
                    for line in reversed(recent_lines):
                        if 'Heartbeat:' in line:
                            match = re.search(r'Heartbeat: (\d+) files, [\d.]+\s*MB, ([\d.]+)\s*MB/s', line)
                            if match:
                                files_processed = int(match.group(1))
                                mb_per_sec = float(match.group(2))
                                current_rate = mb_per_sec * 10  # Rough inodes/sec estimate
                                break

                    return files_processed, current_rate, is_completed

                except Exception:
                    return 0, 0.0, False

            return await loop.run_in_executor(None, parse_log)

        except Exception:
            return 0, 0.0, False

    async def update_verify_status(self) -> None:
        """Update verification status from log file."""
        try:
            if not VERIFY_LOG.exists():
                self.verify_stats = None
                return

            loop = asyncio.get_event_loop()

            def parse_verify_log():
                try:
                    import json
                    import subprocess

                    # Use grep to find the last final_summary (much faster than reading whole file)
                    result = subprocess.run(
                        ['grep', '"type": "final_summary"', str(VERIFY_LOG)],
                        capture_output=True, text=True
                    )

                    verified_count = 0
                    error_count = 0
                    skipped_count = 0
                    last_check = None
                    status = "Idle"
                    display_lines = []

                    with open('/tmp/dash-grep-debug.log', 'w') as df:
                        df.write(f"returncode: {result.returncode}\n")
                        df.write(f"stdout: {len(result.stdout) if result.stdout else 0}\n")

                    if result.returncode == 0 and result.stdout:
                        # Get the last matching line
                        last_summary_line = result.stdout.strip().split('\n')[-1]
                        entry = json.loads(last_summary_line)
                        record = entry.get('record', {})
                        extra = record.get('extra', {})

                        if extra.get('type') == 'final_summary':
                            stats = extra.get('stats', {})
                            verified_count = stats.get('blobs_success', 0)
                            error_count = stats.get('blobs_failed', 0)
                            skipped_count = stats.get('blobs_skipped', 0)
                            status = "Complete"

                            # Get timestamp
                            time_info = record.get('time', {})
                            if time_info:
                                timestamp = time_info.get('repr', '')
                                if timestamp:
                                    last_check = timestamp.split()[1][:8]

                    # Get recent progress lines for display
                    with open(VERIFY_LOG, 'r') as f:
                        recent = f.readlines()[-50:]

                    for line in reversed(recent):
                        try:
                            entry = json.loads(line)
                            text = entry.get('text', '')
                            record = entry.get('record', {})
                            level = record.get('level', {}).get('name', '')

                            if level == 'ERROR':
                                status = "Error"

                            if level not in ['DEBUG'] and len(display_lines) < 10:
                                if '/data/cold/' not in text:
                                    display_lines.append(text.strip())
                        except:
                            continue

                    return {
                        'status': status,
                        'verified': verified_count,
                        'errors': error_count,
                        'skipped': skipped_count,
                        'last_check': last_check or "Never",
                        'recent_lines': list(reversed(display_lines))
                    }

                except Exception as e:
                    import traceback
                    with open("/tmp/ntt-dashboard-verify-error.log", "w") as f:
                        f.write(f"Parse error: {e}\n")
                        f.write(traceback.format_exc())
                    return None

            self.verify_stats = await loop.run_in_executor(None, parse_verify_log)
            with open("/tmp/ntt-dashboard-verify-debug.log", "w") as f:
                f.write(f"verify_stats = {self.verify_stats}\n")

        except Exception as e:
            import traceback
            with open("/tmp/ntt-dashboard-verify-error.log", "a") as f:
                f.write(f"Outer error: {e}\n")
                f.write(traceback.format_exc())

    async def get_memory_stats(self) -> tuple[float, float]:
        """Get memory usage and pressure statistics."""
        try:
            loop = asyncio.get_event_loop()

            def read_memory_info():
                try:
                    with open('/proc/meminfo', 'r') as f:
                        meminfo = {}
                        for line in f:
                            parts = line.split()
                            if len(parts) >= 2:
                                key = parts[0].rstrip(':')
                                value = int(parts[1]) * 1024
                                meminfo[key] = value

                    total = meminfo.get('MemTotal', 0)
                    available = meminfo.get('MemAvailable', 0)

                    if total == 0:
                        return 0.0, 0.0

                    used = total - available
                    usage_pct = (used / total) * 100

                    # Calculate pressure based on available memory
                    available_pct = (available / total) * 100

                    if available_pct < 5:
                        pressure = 95.0
                    elif available_pct < 10:
                        pressure = 80.0
                    elif available_pct < 20:
                        pressure = 60.0
                    elif available_pct < 30:
                        pressure = 40.0
                    else:
                        pressure = 20.0

                    return usage_pct, pressure

                except Exception:
                    return 0.0, 0.0

            return await loop.run_in_executor(None, read_memory_info)

        except Exception:
            return 0.0, 0.0

    async def get_cpu_temperature(self) -> float:
        """Get maximum CPU temperature from thermal zones."""
        try:
            import glob
            loop = asyncio.get_event_loop()

            def read_temps():
                try:
                    max_temp = 0.0

                    thermal_zones = glob.glob('/sys/class/thermal/thermal_zone*/temp')
                    for zone_path in thermal_zones:
                        try:
                            with open(zone_path, 'r') as f:
                                temp = int(f.read().strip()) / 1000.0
                                max_temp = max(max_temp, temp)
                        except (IOError, ValueError):
                            continue

                    if max_temp == 0.0:
                        hwmon_temps = glob.glob('/sys/class/hwmon/hwmon*/temp*_input')
                        for temp_path in hwmon_temps:
                            try:
                                with open(temp_path, 'r') as f:
                                    temp = int(f.read().strip()) / 1000.0
                                    max_temp = max(max_temp, temp)
                            except (IOError, ValueError):
                                continue

                    return max_temp if max_temp > 0 else -1.0

                except Exception:
                    return -1.0

            return await loop.run_in_executor(None, read_temps)

        except Exception:
            return -1.0

    async def get_load_average(self) -> float:
        """Get 1-minute load average."""
        try:
            import os
            load_avg = os.getloadavg()[0]  # 1-minute load average
            return load_avg
        except Exception:
            return 0.0

    async def get_cpu_stats(self) -> tuple[float, float]:
        """Read CPU load and IOwait from /proc/stat."""
        try:
            loop = asyncio.get_event_loop()

            def read_proc_stat():
                try:
                    with open('/proc/stat', 'r') as f:
                        cpu_line = f.readline()

                    parts = cpu_line.split()
                    if len(parts) < 6:
                        return 0.0, 0.0

                    user = int(parts[1])
                    nice = int(parts[2])
                    system = int(parts[3])
                    idle = int(parts[4])
                    iowait = int(parts[5])

                    total = user + nice + system + idle + iowait
                    if total == 0:
                        return 0.0, 0.0

                    if not hasattr(self, 'prev_cpu_stats'):
                        self.prev_cpu_stats = (user + nice + system, idle, iowait, total)
                        return 0.0, 0.0

                    prev_active, prev_idle, prev_iowait, prev_total = self.prev_cpu_stats

                    delta_total = total - prev_total
                    if delta_total == 0:
                        return self.current_cpu_load, self.current_iowait

                    current_active = user + nice + system
                    delta_active = current_active - prev_active
                    delta_iowait = iowait - prev_iowait

                    cpu_load = (delta_active / delta_total) * 100
                    iowait_pct = (delta_iowait / delta_total) * 100

                    self.prev_cpu_stats = (current_active, idle, iowait, total)

                    return cpu_load, iowait_pct

                except Exception:
                    return 0.0, 0.0

            return await loop.run_in_executor(None, read_proc_stat)

        except Exception:
            return 0.0, 0.0

    async def update_system_metrics(self) -> None:
        """Query database for system metrics."""
        if not self.db_conn:
            return

        try:
            loop = asyncio.get_event_loop()

            # Query re-hardlink progress
            def query_hardlink_progress():
                with self.db_conn.cursor() as cur:
                    cur.execute("""
                        SELECT column_name
                        FROM information_schema.columns
                        WHERE table_name = 'blobs'
                        AND column_name = 'expected_hardlinks'
                    """)
                    has_expected_column = cur.fetchone() is not None

                    if has_expected_column:
                        cur.execute("""
                            SELECT
                                COUNT(*) as total_blobs,
                                COUNT(*) FILTER (WHERE n_hardlinks >= expected_hardlinks) as complete_blobs,
                                COUNT(*) FILTER (WHERE n_hardlinks < expected_hardlinks) as incomplete_blobs,
                                SUM(expected_hardlinks) as total_expected,
                                SUM(n_hardlinks) as total_created
                            FROM blobs
                            WHERE expected_hardlinks > 0
                        """)
                        return cur.fetchone()
                    return None

            # Query queue depth
            def query_queue_depth():
                """Get fast queue depth from materialized counter."""
                with self.db_conn.cursor() as cur:
                    cur.execute("""
                        SELECT COALESCE(SUM(unclaimed_count), 0)::int as count
                        FROM queue_stats qs
                        JOIN medium m ON qs.medium_hash = m.medium_hash
                        WHERE m.health = 'ok'
                    """)
                    return cur.fetchone()['count']

            # Query processing stats
            def query_processing_stats():
                with self.db_conn.cursor() as cur:
                    cur.execute("""
                        SELECT
                            COUNT(*) FILTER (WHERE copied = true) as total_processed,
                            COUNT(*) FILTER (WHERE copied = true AND processed_at >= CURRENT_DATE) as today_processed
                        FROM inode
                    """)
                    return cur.fetchone()

            # Query dedup ratio
            def query_hash_dedup():
                with self.db_conn.cursor() as cur:
                    cur.execute("""
                        WITH sample_paths AS (
                            SELECT i.blobid
                            FROM path p
                            JOIN inode i ON i.dev = p.dev AND i.ino = p.ino
                            WHERE i.blobid IS NOT NULL
                            LIMIT 5000
                        )
                        SELECT
                            COUNT(*) as sample_size,
                            COUNT(DISTINCT blobid) as unique_hashes
                        FROM sample_paths
                    """)
                    result = cur.fetchone()

                    if result and result['sample_size'] > 0:
                        return ((result['sample_size'] - result['unique_hashes'])
                               / result['sample_size']) * 100
                    return 0.0

            try:
                queue_depth = await loop.run_in_executor(None, query_queue_depth)
            except Exception as e:
                self.notify(f"Queue depth query error: {e}", severity="error")
                raise

            try:
                stats = await loop.run_in_executor(None, query_processing_stats)
            except Exception as e:
                self.notify(f"Processing stats query error: {e}", severity="error")
                raise

            try:
                dedup_ratio = await loop.run_in_executor(None, query_hash_dedup)
            except Exception as e:
                self.notify(f"Dedup query error: {e}", severity="error")
                raise

            try:
                hardlink_stats = await loop.run_in_executor(None, query_hardlink_progress)
            except Exception as e:
                self.notify(f"Hardlink stats query error: {e}", severity="error")
                raise

            # Calculate processing rate using delta between updates
            current_time = time.time()
            current_processed = stats['total_processed']

            if self.prev_processed_time > 0:
                time_delta = current_time - self.prev_processed_time
                count_delta = current_processed - self.prev_processed_count

                if time_delta > 0 and count_delta >= 0:
                    # Calculate instantaneous rate
                    instant_rate = count_delta / time_delta
                    # Smooth it with exponential moving average
                    processing_rate = self.processing_rate_ema.add(instant_rate)

                    # Store in history for max calculations
                    self.rate_history.append((current_time, instant_rate))

                    # Keep only last 10 minutes of history
                    cutoff_time = current_time - 600  # 10 minutes
                    self.rate_history = [(t, r) for t, r in self.rate_history if t > cutoff_time]
                else:
                    processing_rate = self.processing_rate_ema.ema or 0.0
            else:
                processing_rate = 0.0

            self.prev_processed_count = current_processed
            self.prev_processed_time = current_time

            # Create metrics object
            metrics = SystemMetrics(
                queue_depth=queue_depth,
                files_processed_today=stats['today_processed'],
                total_files_processed=stats['total_processed'],
                processing_rate=processing_rate,
                dedup_ratio=dedup_ratio,
                last_updated=datetime.now()
            )

            # Update reactive attributes
            self.queue_depth = queue_depth
            self.processing_rate = processing_rate

            # Store for history
            self.metrics_history.append(metrics)
            if len(self.metrics_history) > 300:
                self.metrics_history.pop(0)

            # Calculate hardlink rates
            if hardlink_stats:
                current_time = time.time()

                if self.prev_hardlink_stats and self.hardlink_stats_time:
                    time_delta = current_time - self.hardlink_stats_time
                    if time_delta > 0:
                        blobs_delta = hardlink_stats['complete_blobs'] - self.prev_hardlink_stats['complete_blobs']
                        self.hardlink_blob_rate = blobs_delta / time_delta if blobs_delta >= 0 else 0.0

                        if hardlink_stats['total_created'] and self.prev_hardlink_stats['total_created']:
                            links_delta = hardlink_stats['total_created'] - self.prev_hardlink_stats['total_created']
                            self.hardlink_link_rate = links_delta / time_delta if links_delta >= 0 else 0.0
                        else:
                            self.hardlink_link_rate = 0.0

                self.prev_hardlink_stats = hardlink_stats.copy() if hardlink_stats else None
                self.hardlink_stats_time = current_time
                self.hardlink_stats = hardlink_stats
            else:
                self.hardlink_stats = None

        except Exception as e:
            self.notify(f"Metrics query error: {e}", severity="warning")

    def refresh_copier_display(self):
        """Update copier tab displays."""
        # Update worker summary
        try:
            running = len([w for w in self.worker_data if w.status == 'running'])
            completed = len([w for w in self.worker_data if w.status == 'done'])
            failed = len([w for w in self.worker_data if w.status in ('stopped', 'error')])

            # Calculate average CPU for running workers
            running_workers = [w for w in self.worker_data if w.status == 'running']
            avg_cpu = sum(w.cpu_percent for w in running_workers) / len(running_workers) if running_workers else 0

            # Get current timestamp
            from datetime import datetime
            timestamp = datetime.now().strftime("%H:%M:%S")

            if avg_cpu > 0:
                summary = f"{running} running, {completed} completed, {failed} failed (avg CPU: {avg_cpu:.0f}%) @ {timestamp}"
            else:
                summary = f"{running} running, {completed} completed, {failed} failed @ {timestamp}"

            self.query_one("#copier-worker-summary", Label).update(summary)
        except Exception:
            pass

        # Update metrics
        if self.metrics_history:
            latest = self.metrics_history[-1]

            try:
                self.query_one("#copier-queue", Label).update(
                    f"Queue Depth: {latest.queue_depth:,} inodes to process"
                )
                # Calculate 5-minute stats (min, avg, max) and 5-second rate
                current_time = time.time()
                recent_5min = [r for t, r in self.rate_history if t > current_time - 300]

                # Get 5-second instantaneous rate (most recent entry)
                rate_5s = self.rate_history[-1][1] if len(self.rate_history) > 0 else 0

                if len(recent_5min) > 0:
                    min_5min = min(recent_5min)
                    max_5min = max(recent_5min)
                    avg_5min = self.processing_rate_ema.ema or 0.0

                    # Format: "Processing: 3150 inodes/sec (5min: 2800 min, 3050 avg, 3200 max)"
                    rate_text = f"Processing: {int(rate_5s)} inodes/sec (5min: {int(min_5min)} min, {int(avg_5min)} avg, {int(max_5min)} max)"
                else:
                    rate_text = f"Processing: {int(rate_5s)} inodes/sec"

                self.query_one("#copier-rate", Label).update(rate_text)

                # Update plotext graph
                if len(self.rate_history) > 0:
                    graph = self.query_one("#copier-rate-graph", ThroughputGraph)
                    graph.update_data(self.rate_history)
                self.query_one("#copier-today", Label).update(
                    f"Today: {latest.files_processed_today:,} inodes"
                )
                self.query_one("#copier-total", Label).update(
                    f"Total: {latest.total_files_processed:,} inodes"
                )

                # Calculate ETA using 5-min statistics
                if latest.queue_depth > 0 and len(recent_5min) > 0:
                    min_5min = min(recent_5min)
                    max_5min = max(recent_5min)
                    avg_5min = self.processing_rate_ema.ema or 0.0

                    if avg_5min > 0:
                        # Average ETA
                        eta_avg_seconds = latest.queue_depth / avg_5min
                        # Range: best case (max rate) to worst case (min rate)
                        eta_best_seconds = latest.queue_depth / max_5min if max_5min > 0 else 0
                        eta_worst_seconds = latest.queue_depth / min_5min if min_5min > 0 else 0

                        def format_time(seconds):
                            if seconds < 60:
                                return f"{int(seconds)}s"
                            elif seconds < 3600:
                                mins = int(seconds / 60)
                                secs = int(seconds % 60)
                                return f"{mins}m {secs}s"
                            else:
                                hrs = int(seconds / 3600)
                                mins = int((seconds % 3600) / 60)
                                return f"{hrs}h {mins}m"

                        eta_text = f"ETA: {format_time(eta_avg_seconds)} (range: {format_time(eta_best_seconds)} - {format_time(eta_worst_seconds)})"
                        self.query_one("#copier-eta", Label).update(eta_text)
                    else:
                        self.query_one("#copier-eta", Label).update("ETA: --")
                else:
                    self.query_one("#copier-eta", Label).update("ETA: --")

                self.query_one("#copier-dedup", Label).update(
                    f"Dedup: {latest.dedup_ratio:.1f}%"
                )
            except Exception:
                pass

    def refresh_hardlink_display(self):
        """Update re-hardlink tab displays."""
        if not self.hardlink_stats:
            return

        stats = self.hardlink_stats

        try:
            self.query_one("#hl-total", Label).update(
                f"Total Blobs: {stats['total_blobs']:,}"
            )
            self.query_one("#hl-complete", Label).update(
                f"Complete: {stats['complete_blobs']:,}"
            )
            self.query_one("#hl-incomplete", Label).update(
                f"Incomplete: {stats['incomplete_blobs']:,}"
            )

            if stats['total_blobs'] > 0:
                progress = (stats['complete_blobs'] / stats['total_blobs']) * 100
                self.query_one("#hl-progress", Label).update(
                    f"Progress: {progress:.1f}%"
                )

                # Calculate ETA
                if self.hardlink_blob_rate > 0 and stats['incomplete_blobs'] > 0:
                    eta_seconds = stats['incomplete_blobs'] / self.hardlink_blob_rate
                    if eta_seconds < 3600:
                        eta_str = f"{int(eta_seconds / 60)} min"
                    elif eta_seconds < 86400:
                        eta_str = f"{eta_seconds / 3600:.1f} hrs"
                    else:
                        eta_str = f"{eta_seconds / 86400:.1f} days"
                    self.query_one("#hl-eta", Label).update(f"Est. Time: {eta_str}")
                else:
                    self.query_one("#hl-eta", Label).update("Est. Time: --")

            if stats['total_expected'] and stats['total_created']:
                created_pct = (stats['total_created'] / stats['total_expected']) * 100
                self.query_one("#hl-links", Label).update(
                    f"Links: {stats['total_created']:,}/{stats['total_expected']:,} ({created_pct:.1f}%)"
                )

            # Update rates with color coding
            blob_rate_label = self.query_one("#hl-blob-rate", Label)
            if self.hardlink_blob_rate > 0:
                blob_rate_label.update(f"Blob Rate: {self.hardlink_blob_rate:.1f} blobs/sec")
                if self.hardlink_blob_rate > 200:
                    blob_rate_label.styles.color = "green"
                elif self.hardlink_blob_rate > 100:
                    blob_rate_label.styles.color = "cyan"
                else:
                    blob_rate_label.styles.color = "yellow"
            else:
                blob_rate_label.update("Blob Rate: --")

            link_rate_label = self.query_one("#hl-link-rate", Label)
            if self.hardlink_link_rate > 0:
                link_rate_label.update(f"Link Rate: {self.hardlink_link_rate:.0f} links/sec")
                if self.hardlink_link_rate > 10000:
                    link_rate_label.styles.color = "green"
                elif self.hardlink_link_rate > 5000:
                    link_rate_label.styles.color = "cyan"
                else:
                    link_rate_label.styles.color = "yellow"
            else:
                link_rate_label.update("Link Rate: --")

        except Exception:
            pass

    def refresh_verify_display(self):
        """Update verify tab displays."""
        if not self.verify_stats:
            try:
                self.query_one("#verify-status-label", Label).update("Status: Not Running")
                self.query_one("#verify-count", Label).update("Verified: --")
                self.query_one("#verify-errors", Label).update("Errors: --")
                self.query_one("#verify-rate", Label).update("Rate: --")
                self.query_one("#verify-last", Label).update("Last Check: --")
            except Exception:
                pass
            return

        stats = self.verify_stats

        try:
            # Update status with color
            status_label = self.query_one("#verify-status-label", Label)
            status_label.update(f"Status: {stats['status']}")
            if stats['status'] == "Running":
                status_label.styles.color = "green"
            elif stats['status'] == "Error":
                status_label.styles.color = "red"
            elif stats['status'] == "Complete":
                status_label.styles.color = "cyan"
            else:
                status_label.styles.color = "dim"

            # Show verified count with skipped info
            verified_text = f"Verified: {stats['verified']:,}"
            if stats.get('skipped', 0) > 0:
                verified_text += f" ({stats['skipped']:,} skipped)"
            self.query_one("#verify-count", Label).update(verified_text)

            # Update errors with color
            error_label = self.query_one("#verify-errors", Label)
            error_label.update(f"Errors: {stats['errors']}")
            if stats['errors'] > 0:
                error_label.styles.color = "red"
            else:
                error_label.styles.color = "green"

            # Calculate rate (placeholder for now)
            self.query_one("#verify-rate", Label).update("Rate: --")

            self.query_one("#verify-last", Label).update(f"Last Check: {stats['last_check']}")

            # Update log view with recent lines
            log_view = self.query_one("#verify-log-view", Log)
            if 'recent_lines' in stats:
                for line in stats['recent_lines']:
                    if line.strip():
                        log_view.write_line(line.strip())

        except Exception:
            pass

    def on_unmount(self) -> None:
        """Cleanup on exit."""
        if self.update_timer:
            self.update_timer.stop()

        if self.db_conn:
            self.db_conn.close()


def main():
    """Entry point for dashboard application."""
    app = NTTDashboard()
    app.run()


if __name__ == "__main__":
    main()
