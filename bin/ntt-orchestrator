#!/usr/bin/env bash
# Author: PB, Claude, Kimi
# Date: 2025-09-26
# License: (c) HRDAG, 2025, GPL-2 or newer
#
# ------
# ntt/bin/ntt-orchestrator
#
# NTT ingest dispatcher – supports both device and directory modes
# Note: Must be run with sudo/root privileges for device operations
set -eo pipefail
PATH="/home/pball/projects/ntt/bin:$PATH"

# NTT bin directory
NTT_BIN="${NTT_BIN:-/home/pball/projects/ntt/bin}"

# Global variables for cleanup tracking
CLEANUP_NEEDED=false
MOUNT_POINT=""
LOOP_DEVICE=""

# Cleanup trap for error handling
cleanup() {
  local exit_code=$?
  if [[ "$CLEANUP_NEEDED" == "true" ]]; then
    if [[ -n "$MOUNT_POINT" ]] && mount | grep -q "$MOUNT_POINT"; then
      echo "[$(date -Iseconds)] Cleaning up mount: $MOUNT_POINT" >&2
      umount "$MOUNT_POINT" 2>/dev/null || true
    fi
    if [[ -n "$LOOP_DEVICE" ]] && losetup -l | grep -q "$LOOP_DEVICE"; then
      echo "[$(date -Iseconds)] Cleaning up loop device: $LOOP_DEVICE" >&2
      losetup -d "$LOOP_DEVICE" 2>/dev/null || true
    fi
    if [[ -n "$MOUNT_POINT" ]] && [[ -d "$MOUNT_POINT" ]]; then
      rmdir "$MOUNT_POINT" 2>/dev/null || true
    fi
  fi
  exit $exit_code
}
trap cleanup EXIT INT TERM

# Check if running as root
if [[ $EUID -ne 0 ]]; then
   echo "Error: This script must be run with sudo or as root" >&2
   echo "Usage: sudo $0 <target> [options]" >&2
   exit 1
fi

# ---------- source config ----------
# Source config from actual user's home (not root's ~)
if [[ -n "$SUDO_USER" ]]; then
  USER_HOME=$(eval echo ~$SUDO_USER)
  CONFIG_FILE="$USER_HOME/.config/ntt/ntt.env"
else
  CONFIG_FILE=~/.config/ntt/ntt.env
fi

if [[ -f "$CONFIG_FILE" ]]; then
  source "$CONFIG_FILE"
else
  # Fallback: use original user when running under sudo
  export PGUSER="${SUDO_USER:-$USER}"
fi

# ---------- config ----------
DB_URL="${NTT_DB_URL:-postgres:///copyjob}"
DB_USER="${PGUSER:-${SUDO_USER:-$USER}}"
IMAGE_ROOT="${NTT_IMAGE_ROOT:-/data/fast/img}"
RAW_ROOT="${NTT_RAW_ROOT:-/data/fast/raw}"
DST_ROOT="${NTT_DST_ROOT:-/data/cold/dst}"
LOG_JSON="${NTT_ORCHESTRATOR_LOG:-/var/log/ntt/orchestrator.jsonl}"
DIAGNOSTICS=""  # Global variable for storing device/image diagnostics
mkdir -p "$(dirname "$LOG_JSON")"
chmod 755 "$(dirname "$LOG_JSON")" 2>/dev/null || true

# Wrapper for psql that handles running as root
psql_as_user() {
  if [[ $EUID -eq 0 ]] && [[ -n "$DB_USER" ]] && [[ "$DB_USER" != "root" ]]; then
    sudo -u "$DB_USER" psql -q "$@" 2>/dev/null
  else
    psql -q "$@" 2>/dev/null
  fi
}

# ---------- logging functions ----------
log() {
  jq -cn --arg ts "$(date -Iseconds)" \
        --arg stage "$1" \
        --argjson extra "$2" \
        '$extra + {ts: $ts, stage: $stage}' \
  >> "$LOG_JSON"
  chmod 644 "$LOG_JSON" 2>/dev/null || true
}

fail() {
  echo "Error: $1" >&2
  log error "{\"msg\": \"$1\"}"
  exit 1
}

# ---------- identification functions ----------
get_real_hardware_info() {
  # Get actual drive hardware info, bypassing USB bridges
  # Sets global variables: MODEL, SERIAL
  #
  # Args: $1 = device path (e.g., /dev/sdd)
  #
  # Strategy:
  #   1. Try smartctl with USB-SAT protocols (bypasses USB/SATA bridges)
  #   2. Fallback to hdparm (also bypasses bridges)
  #   3. Final fallback to lsblk (may show bridge info)

  local dev="$1"
  MODEL=""
  SERIAL=""

  # Try smartctl first - attempt multiple USB bridge protocols
  if command -v smartctl &>/dev/null; then
    # Try direct access first (works for native SATA)
    local smart_model=$(smartctl -i "$dev" 2>/dev/null | grep "Device Model:" | awk '{$1=$2=""; print $0}' | xargs)
    local smart_serial=$(smartctl -i "$dev" 2>/dev/null | grep "Serial Number:" | awk '{$1=$2=""; print $0}' | xargs)

    # Check if we got real drive info (not USB bridge/adapter)
    if [[ -n "$smart_model" ]] && [[ ! "$smart_model" =~ (Dual|USB|Bridge|Adapter) ]]; then
      MODEL=$(echo "$smart_model" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
      SERIAL=$(echo "$smart_serial" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
      echo "[$(date -Iseconds)] Hardware info: smartctl direct → MODEL=$MODEL SERIAL=$SERIAL" >&2
      return 0
    fi

    # Try USB-SAT protocols (for USB-attached drives)
    for protocol in "sat" "sat,12" "sat,16" "usbsunplus" "usbcypress" "usbjmicron"; do
      smart_model=$(smartctl -d "$protocol" -i "$dev" 2>/dev/null | grep "Device Model:" | awk '{$1=$2=""; print $0}' | xargs)
      smart_serial=$(smartctl -d "$protocol" -i "$dev" 2>/dev/null | grep "Serial Number:" | awk '{$1=$2=""; print $0}' | xargs)

      # Check if we got real drive info
      if [[ -n "$smart_model" ]] && [[ ! "$smart_model" =~ (Dual|USB|Bridge|Adapter) ]]; then
        MODEL=$(echo "$smart_model" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
        SERIAL=$(echo "$smart_serial" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
        echo "[$(date -Iseconds)] Hardware info: smartctl -d $protocol → MODEL=$MODEL SERIAL=$SERIAL" >&2
        return 0
      fi
    done
  fi

  # Fallback to hdparm
  if command -v hdparm &>/dev/null; then
    local hdparm_model=$(sudo hdparm -I "$dev" 2>/dev/null | grep "Model Number:" | awk -F: '{print $2}' | xargs)
    local hdparm_serial=$(sudo hdparm -I "$dev" 2>/dev/null | grep "Serial Number:" | awk -F: '{print $2}' | xargs)

    if [[ -n "$hdparm_model" ]]; then
      MODEL=$(echo "$hdparm_model" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
      SERIAL=$(echo "$hdparm_serial" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
      echo "[$(date -Iseconds)] Hardware info: hdparm → MODEL=$MODEL SERIAL=$SERIAL" >&2
      return 0
    fi
  fi

  # Final fallback to lsblk (may show USB bridge for USB-attached drives)
  MODEL=$(lsblk -no MODEL "$dev" 2>/dev/null | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
  SERIAL=$(lsblk -no SERIAL "$dev" 2>/dev/null | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
  echo "[$(date -Iseconds)] Hardware info: lsblk fallback → MODEL=$MODEL SERIAL=$SERIAL" >&2
}

identify_device() {
  local dev="$1"
  local user_message="$2"

  if [[ ! -e "$dev" ]]; then
    fail "Device $dev not found"
  fi

  echo "[$(date -Iseconds)] Identifying device $dev..." >&2

  # Wait for optical drives to be ready (CD/DVD/Blu-ray)
  if [[ "$dev" =~ ^/dev/sr[0-9]+$ ]]; then
    echo "[$(date -Iseconds)] Optical drive detected, waiting for media to be ready..." >&2
    local max_wait=30  # seconds
    local elapsed=0

    while [[ $elapsed -lt $max_wait ]]; do
      # Try to read a small amount - if it succeeds, media is ready
      if dd if="$dev" of=/dev/null bs=512 count=1 status=none 2>/dev/null; then
        echo "[$(date -Iseconds)] Media ready after ${elapsed}s" >&2
        break
      fi
      sleep 1
      elapsed=$((elapsed + 1))
    done

    if [[ $elapsed -ge $max_wait ]]; then
      fail "Optical drive timeout: media not ready after ${max_wait}s"
    fi
  fi

  # Detect removable devices FIRST (lsblk doesn't access device, so it's safe)
  local removable=$(lsblk -no HOTPLUG "$dev" 2>/dev/null || echo 0)
  local is_small_or_removable=false
  local dev_sectors=0
  local dev_size_mb=0

  # If removable, assume it's small/problematic and skip device access
  if [[ "$removable" == "1" ]]; then
    is_small_or_removable=true
    dev_sectors=2880  # Typical floppy size for naming purposes
    dev_size_mb=1
  else
    # Only try to get size if not removable (blockdev can hang on floppies)
    dev_sectors=$(blockdev --getsz "$dev" 2>/dev/null || echo 2048)
    dev_size_mb=$((dev_sectors * 512 / 1024 / 1024))
    if [[ $dev_size_mb -lt 10 ]]; then
      is_small_or_removable=true
    fi
  fi

  # Comprehensive device diagnostics BEFORE content hash
  local DIAG_FILE="/tmp/ntt-diag-$$"
  {
    echo "=== DISK HARDWARE INFO ==="

    # Skip hdparm/smartctl for small/removable devices (they hang on floppies)
    if [[ "$is_small_or_removable" == "true" ]]; then
      echo "--- hdparm identity ---"
      echo "Skipped for small/removable device"
      echo ""
    else
      echo "--- hdparm identity ---"
      sudo hdparm -I "$dev" 2>&1 || echo "hdparm failed"
      echo ""
    fi

    echo "--- lsblk overview ---"
    lsblk "$dev" 2>&1 || echo "lsblk failed"
    echo ""
    echo "--- fdisk partition table ---"
    sudo fdisk -l "$dev" 2>&1 || echo "fdisk failed"
    echo ""

    # Skip parted for small/removable devices (hangs on floppies)
    if [[ "$is_small_or_removable" == "true" ]]; then
      echo "--- parted partition info ---"
      echo "Skipped for small/removable device"
      echo ""
    else
      echo "--- parted partition info ---"
      sudo parted "$dev" print 2>&1 || echo "parted failed"
      echo ""
    fi

    echo "=== HEALTH & SMART DATA ==="
    if [[ "$is_small_or_removable" == "true" ]]; then
      echo "Skipped for small/removable device"
      echo ""
    else
      # NOTE: For partitions (e.g., /dev/sdc1), USB bridges may block SMART access.
      # Always check parent device (e.g., /dev/sdc) for real disk SMART data.
      # TODO: Auto-detect partition and query parent device for SMART
      sudo smartctl -a "$dev" 2>&1 || echo "smartctl failed or not available"
      echo ""
    fi

    echo "=== CONTENT ANALYSIS ==="
    # Skip content analysis for small/removable devices (they hang on floppies)
    if [[ "$is_small_or_removable" == "true" ]]; then
      echo "Skipped for small/removable device (will analyze from image)"
    else
      echo "--- file signature ---"
      sudo file -s "$dev" 2>&1 || echo "file failed"
      echo ""
      echo "--- wipefs signatures ---"
      sudo wipefs "$dev" 2>&1 || echo "wipefs failed"
      echo ""
      echo "--- blkid UUIDs ---"
      sudo blkid "$dev"* 2>&1 || echo "blkid failed"
      echo ""
      echo "--- MBR/first sector (512 bytes hex dump) ---"
      sudo dd if="$dev" bs=512 count=1 2>/dev/null | xxd 2>&1 || echo "dd/xxd failed"
    fi
  } > "$DIAG_FILE"

  # Store diagnostics for database insertion
  DIAGNOSTICS=$(cat "$DIAG_FILE")
  rm -f "$DIAG_FILE"

  # Get hardware info BEFORE hash generation (needed for metadata)
  MODEL=""
  SERIAL=""

  if [[ "$is_small_or_removable" != "true" ]]; then
    # Fixed disk - detect device type and get hardware info
    local dev_type=$(lsblk -no TYPE "$dev" 2>/dev/null)
    local dev_tran=$(lsblk -no TRAN "$dev" 2>/dev/null)

    if [[ "$dev_type" == "rom" ]]; then
      # CD-ROM/DVD: use lsblk (smartctl may not work on optical drives)
      MODEL=$(lsblk -no MODEL "$dev" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
      SERIAL=$(lsblk -no SERIAL "$dev" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
    elif [[ "$dev_tran" == "usb" ]] || [[ "$dev_tran" == "sata" ]] || [[ "$dev_tran" == "ata" ]]; then
      # USB/SATA/ATA disk: use smartctl/hdparm (bypasses USB bridges)
      get_real_hardware_info "$dev"
    else
      # Unknown transport: fallback to lsblk
      MODEL=$(lsblk -no MODEL "$dev" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
      SERIAL=$(lsblk -no SERIAL "$dev" | tr -s ' ' '_' | tr -cd '[:alnum:]_-' | cut -c1-64)
    fi
  fi

  echo "[$(date -Iseconds)] Generating content hash with metadata..." >&2

  # Get exact device size in bytes
  local dev_size_bytes=$(blockdev --getsize64 "$dev" 2>/dev/null || echo "0")

  # Build metadata string for hash (ensures unique hashes per physical device)
  local hash_metadata="SIZE:${dev_size_bytes}|MODEL:${MODEL:-unknown}|SERIAL:${SERIAL:-unknown}|"
  echo "[$(date -Iseconds)] Hash metadata: $hash_metadata" >&2

  # Create signature file with metadata prepended to content
  SIG_FILE="/tmp/ntt-sig-$$"

  # Write metadata header first
  echo -n "$hash_metadata" > "$SIG_FILE"

  # Append first 1MB (up to 2048 sectors of 512 bytes)
  # conv=noerror,sync continues on read errors and pads with zeros
  # Use >> redirection instead of oflag=append (which doesn't work with conv=noerror,sync)
  dd if="$dev" bs=512 count=2048 conv=noerror,sync status=none 2>/dev/null >> "$SIG_FILE" || true

  # Append last 1MB (skip to end - 1MB, or start if device < 1MB)
  # dev_sectors already calculated above
  local skip_sectors=$((dev_sectors - 2048))
  if [[ $skip_sectors -lt 0 ]]; then
    skip_sectors=0
  fi
  dd if="$dev" bs=512 skip=$skip_sectors count=2048 conv=noerror,sync status=none 2>/dev/null >> "$SIG_FILE" || true

  # Generate hash from metadata + content
  local medium_hash=$(b3sum < "$SIG_FILE" | cut -d' ' -f1 | cut -c1-32)
  rm -f "$SIG_FILE"

  # Store hash metadata in diagnostics for forensic analysis
  DIAGNOSTICS="${DIAGNOSTICS}

=== HASH METADATA ===
$hash_metadata"

  # Human name - use different strategy for removable media vs fixed disks
  # (removable and dev_size_mb already calculated above)
  if [[ "$is_small_or_removable" == "true" ]]; then
    # Removable media (floppy, USB stick, etc) or very small device
    # Use: floppy_YYYYMMDD_HHMMSS_hashprefix
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local hash_prefix="${medium_hash:0:8}"
    local medium_human="floppy_${timestamp}_${hash_prefix}"
  else
    # Fixed disk - use hardware info already retrieved above
    local medium_human="${MODEL:-unknown}_${SERIAL:-unknown}"
  fi

  log identify "{\"medium_hash\":\"$medium_hash\",\"medium_human\":\"$medium_human\",\"message\":\"$user_message\",\"dev\":\"$dev\"}"

  echo "[$(date -Iseconds)] Identified as: $medium_human (hash: $medium_hash)" >&2

  # Return: hash:human:message (diagnostics stored in global DIAGNOSTICS variable)
  echo "$medium_hash:$medium_human:$user_message"
}

identify_path() {
  local path="$1"

  if [[ ! -d "$path" ]]; then
    fail "Path $path not found or not a directory"
  fi

  # Generate hash from path only (consistent across runs)
  local medium_human="$(basename "$path")"
  local medium_hash=$(echo -n "$path" | b3sum | cut -d' ' -f1 | cut -c1-32)

  log identify "{\"medium_human\": \"$medium_human\", \"medium_hash\": \"$medium_hash\", \"path\": \"$path\"}"

  # Return values via echo
  echo "$medium_hash:$medium_human"
}

identify_image() {
  local image_path="$1"
  local user_message="${2:-}"

  if [[ ! -f "$image_path" ]]; then
    fail "Image file not found: $image_path"
  fi

  local filename=$(basename "$image_path")
  local base="${filename%.*}"
  local medium_hash=""
  local medium_human=""

  # Check if filename is a medium_hash (32 hex chars)
  if [[ "$base" =~ ^[a-f0-9]{32}$ ]]; then
    # Filename IS the medium_hash from original device imaging
    medium_hash="$base"
    echo "[$(date -Iseconds)] Using hash from filename: $medium_hash" >&2

    # Look up medium_human from database if exists
    local existing_human=$(psql_as_user "$DB_URL" -tAc "SELECT medium_human FROM medium WHERE medium_hash = '$medium_hash'" 2>/dev/null | tr -d ' ')

    if [[ -n "$existing_human" ]]; then
      medium_human="$existing_human"
      echo "[$(date -Iseconds)] Found existing medium: $medium_human" >&2

      # Capture minimal diagnostics
      DIAGNOSTICS="=== IMAGE METADATA ===
Image path: $image_path
Re-processing existing medium (hash from filename)
"
    else
      # Not in database - treat as new
      medium_human="${base:0:16}"
      echo "[$(date -Iseconds)] Hash-named image not in database, treating as new" >&2

      # Capture full diagnostics
      local DIAG_FILE="/tmp/ntt-img-diag-$$"
      {
        echo "=== IMAGE METADATA ==="
        echo "Image path: $image_path"
        echo "Size: $(stat -c %s "$image_path") bytes ($(stat -c %s "$image_path" | numfmt --to=iec-i --suffix=B 2>/dev/null || stat -c %s "$image_path"))"
        echo "Modified: $(stat -c %y "$image_path")"
        echo ""
        echo "=== FILESYSTEM SIGNATURE ==="
        file -s "$image_path" 2>&1 || echo "file command failed"
        echo ""
        echo "=== BLKID OUTPUT ==="
        echo "(Captured after loop device creation in mount_image)"
      } > "$DIAG_FILE"

      cp "$DIAG_FILE" "/tmp/ntt-image-diag-$$"
      DIAGNOSTICS=$(cat "$DIAG_FILE")
      rm -f "$DIAG_FILE"
    fi
  else
    # Arbitrary filename - compute content-based hash (original behavior)
    medium_human="$base"
    echo "[$(date -Iseconds)] Computing content hash for arbitrary image: $filename" >&2

    # Capture diagnostics
    local DIAG_FILE="/tmp/ntt-img-diag-$$"
    {
      echo "=== IMAGE METADATA ==="
      echo "Image path: $image_path"
      echo "Size: $(stat -c %s "$image_path") bytes ($(stat -c %s "$image_path" | numfmt --to=iec-i --suffix=B 2>/dev/null || stat -c %s "$image_path"))"
      echo "Modified: $(stat -c %y "$image_path")"
      echo ""
      echo "=== FILESYSTEM SIGNATURE ==="
      file -s "$image_path" 2>&1 || echo "file command failed"
      echo ""
      echo "=== BLKID OUTPUT ==="
      echo "(Captured after loop device creation in mount_image)"
    } > "$DIAG_FILE"

    cp "$DIAG_FILE" "/tmp/ntt-image-diag-$$"
    DIAGNOSTICS=$(cat "$DIAG_FILE")
    rm -f "$DIAG_FILE"

    # Generate content hash
    SIG_FILE="/tmp/ntt-sig-$$"
    head -c 1M "$image_path" > "$SIG_FILE"
    tail -c 1M "$image_path" >> "$SIG_FILE"
    medium_hash=$(b3sum < "$SIG_FILE" | cut -d' ' -f1 | cut -c1-32)
    rm -f "$SIG_FILE"
  fi

  log identify "{\"medium_human\": \"$medium_human\", \"medium_hash\": \"$medium_hash\", \"message\": \"$user_message\", \"image\": \"$image_path\"}"
  echo "[$(date -Iseconds)] Identified as: $medium_human (hash: $medium_hash)" >&2

  # Return: hash:human:message (diagnostics stored in global DIAGNOSTICS variable)
  echo "$medium_hash:$medium_human:$user_message"
}

# ---------- health check functions ----------
check_device_health() {
  local dev="$1"

  local SMART_FAIL=$(smartctl -H "$dev" 2>/dev/null | grep -c "FAILED" || echo 0)
  local PROPRIETARY=$(smartctl -i "$dev" 2>/dev/null | grep -Ei "G-RAID|hardware-raid" | wc -l || echo 0)
  local REMOVABLE=$(lsblk -no HOTPLUG "$dev" 2>/dev/null || echo 0)

  local IMAGE_FIRST=false
  if [[ $SMART_FAIL -gt 0 ]] || [[ $PROPRIETARY -gt 0 ]] || [[ "$REMOVABLE" == "1" ]]; then
    IMAGE_FIRST=true
  fi

  log health "{\"image_first\": $IMAGE_FIRST, \"smart_fail\": $SMART_FAIL, \"proprietary\": $PROPRIETARY}"

  # Return the value
  echo "$IMAGE_FIRST"
}

update_health_from_mapfile() {
  local medium_hash="$1"
  local mapfile="$2"

  if [[ ! -f "$mapfile" ]]; then
    echo "[$(date -Iseconds)] WARNING: Mapfile not found: $mapfile, setting health=ok by default" >&2
    psql_as_user "$DB_URL" -c "UPDATE medium SET health = 'ok' WHERE medium_hash = '$medium_hash';" 2>/dev/null || true
    return
  fi

  # Parse rescue percentage from mapfile (same logic as ntt-imager)
  # Mapfile format: pos(hex) size(hex) status
  # Status: + (rescued), - (bad), ? (non-tried), * (non-trimmed), / (non-scraped)
  local rescued=$(grep -v '^#' "$mapfile" 2>/dev/null | awk 'NF==3 && $2 ~ /^0x/ && $3=="+" {sum+=strtonum($2)} END {print sum+0}')
  local total=$(grep -v '^#' "$mapfile" 2>/dev/null | awk 'NF==3 && $2 ~ /^0x/ {sum+=strtonum($2)} END {print sum+0}')

  local rescued_pct="0.00"
  if [[ $total -eq 0 ]]; then
    rescued_pct="0.00"
  else
    rescued_pct=$(echo "scale=2; $rescued * 100 / $total" | bc)
  fi

  # Determine health based on rescue percentage
  local health="failed"
  if (( $(echo "$rescued_pct == 100" | bc -l) )); then
    health="ok"
  elif (( $(echo "$rescued_pct >= 90" | bc -l) )); then
    health="incomplete"
  elif (( $(echo "$rescued_pct >= 20" | bc -l) )); then
    health="corrupt"
  else
    health="failed"
  fi

  echo "[$(date -Iseconds)] Updating health: ${rescued_pct}% rescued → health=$health" >&2
  log health_update "{\"medium_hash\": \"$medium_hash\", \"rescued_pct\": \"$rescued_pct\", \"health\": \"$health\"}"

  # Update database
  psql_as_user "$DB_URL" -c "UPDATE medium SET health = '$health' WHERE medium_hash = '$medium_hash';" 2>/dev/null || true
}

# ---------- pipeline state functions ----------
check_pipeline_state() {
  local medium_hash="$1"

  # Check if image exists
  local image_path=$(psql_as_user "$DB_URL" -tAc "SELECT image_path FROM medium WHERE medium_hash = '$medium_hash'" 2>/dev/null)
  local has_image=false
  if [[ -n "$image_path" ]] && [[ -f "$image_path" ]]; then
    has_image=true
  fi

  # Check if currently mounted
  local is_mounted=false
  if mount | grep -q "/mnt/ntt/${medium_hash}"; then
    is_mounted=true
  fi

  # Check if inodes enumerated
  local inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
  local has_inodes=false
  if [[ $inode_count -gt 0 ]]; then
    has_inodes=true
  fi

  # Check if paths loaded
  local path_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM path WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
  local has_paths=false
  if [[ $path_count -gt 0 ]]; then
    has_paths=true
  fi

  # Check if copying is complete
  local is_copying_done=false
  if [[ $inode_count -gt 0 ]]; then
    local pending_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash' AND copied = false AND claimed_by IS NULL" 2>/dev/null || echo "0")
    if [[ $pending_count -eq 0 ]]; then
      is_copying_done=true
    fi
  fi

  # Return state as colon-separated values
  # Format: has_image:is_mounted:has_inodes:has_paths:is_copying_done:inode_count:path_count
  echo "$has_image:$is_mounted:$has_inodes:$has_paths:$is_copying_done:$inode_count:$path_count"
}

# ---------- pipeline stage functions ----------
# Stage functions return: 0=success, 1=skip/already done, 2=fatal error

stage_mount() {
  local medium_hash="$1"

  echo "[$(date -Iseconds)] STAGE: Mount" >&2

  # Check if already mounted
  if "$NTT_BIN/ntt-mount-helper" status "$medium_hash" >/dev/null 2>&1; then
    echo "[$(date -Iseconds)] Already mounted, skipping" >&2
    return 1
  fi

  # Get image path from database
  local image_path=$(psql_as_user "$DB_URL" -tAc "SELECT image_path FROM medium WHERE medium_hash = '$medium_hash'" 2>/dev/null)
  if [[ -z "$image_path" ]]; then
    echo "[$(date -Iseconds)] ERROR: No image_path in database for $medium_hash" >&2
    log mount_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"no_image_path\"}"
    return 2
  fi

  if [[ ! -f "$image_path" ]]; then
    echo "[$(date -Iseconds)] ERROR: Image file not found: $image_path" >&2
    log mount_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"image_not_found\", \"path\": \"$image_path\"}"
    return 2
  fi

  # Check health before mounting (only refuse 'failed' - allow ok/incomplete/corrupt)
  local health=$(psql_as_user "$DB_URL" -tAc "SELECT health FROM medium WHERE medium_hash = '$medium_hash'" 2>/dev/null)
  if [[ "$health" == "failed" ]]; then
    echo "[$(date -Iseconds)] ERROR: Refusing to mount - health=failed (<20% rescued)" >&2
    log mount_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"bad_health\", \"health\": \"$health\"}"

    # Mark all inodes as EXCLUDED
    psql_as_user "$DB_URL" <<SQL
UPDATE inode
SET copied = true, claimed_by = 'EXCLUDED: bad_health', claimed_at = NOW()
WHERE medium_hash = '$medium_hash' AND copied = false;
SQL
    return 2
  fi

  # Log health status if not perfect
  if [[ -n "$health" ]] && [[ "$health" != "ok" ]]; then
    echo "[$(date -Iseconds)] WARNING: Mounting with health=$health (degraded media, expect errors)" >&2
    log mount_warning "{\"medium_hash\": \"$medium_hash\", \"health\": \"$health\", \"msg\": \"mounting_degraded_media\"}"
  fi

  # Use ntt-mount-helper for mounting (captures JSON output)
  echo "[$(date -Iseconds)] Mounting $image_path" >&2
  local mount_output
  mount_output=$("$NTT_BIN/ntt-mount-helper" mount "$medium_hash" "$image_path" 2>&1)
  local mount_rc=$?

  if [[ $mount_rc -eq 0 ]]; then
    # Parse JSON output to detect layout
    # Extract complete JSON (from first { to end of output)
    local json_line=$(echo "$mount_output" | sed -n '/^{/,$ p' | tr -d '\n')

    if [[ -n "$json_line" ]]; then
      # Store mount metadata in temp file for stage_enum
      echo "$json_line" > "/tmp/ntt-mount-meta-${medium_hash}"

      local layout=$(echo "$json_line" | jq -r '.layout')
      echo "[$(date -Iseconds)] Mount successful: layout=$layout" >&2
      log mount_success "{\"medium_hash\": \"$medium_hash\", \"image_path\": \"$image_path\", \"layout\": \"$layout\"}"

      # Parse and store LVM metadata if present
      local lvm_info=""
      local lvm_count=$(echo "$json_line" | jq '[.partitions[] | select(.lvm != null)] | length')

      if [[ "$lvm_count" -gt 0 ]]; then
        echo "[$(date -Iseconds)] Found $lvm_count LVM partition(s), extracting metadata..." >&2

        # Build LVM metadata summary
        lvm_info="=== LVM METADATA ===\n"
        lvm_info+="Found $lvm_count LVM physical volume(s)\n\n"

        # Extract each LVM partition's metadata
        local part_idx=0
        while true; do
          local lvm_data=$(echo "$json_line" | jq -r ".partitions[$part_idx].lvm // empty" 2>/dev/null)
          [[ -z "$lvm_data" || "$lvm_data" == "null" ]] && { ((part_idx++)) || true; [[ $part_idx -ge 10 ]] && break; continue; }

          local part_num=$(echo "$json_line" | jq -r ".partitions[$part_idx].num")
          local lvm_type=$(echo "$lvm_data" | jq -r '.lvm_type')
          local pv_uuid=$(echo "$lvm_data" | jq -r '.pv_uuid')
          local vg_name=$(echo "$lvm_data" | jq -r '.vg_name')
          local lv_names=$(echo "$lvm_data" | jq -r '.lv_names | join(", ")')

          lvm_info+="Partition p${part_num}:\n"
          lvm_info+="  Type: $lvm_type\n"
          lvm_info+="  PV UUID: $pv_uuid\n"
          lvm_info+="  VG Name: $vg_name\n"
          lvm_info+="  LV Names: $lv_names\n\n"

          ((part_idx++)) || true
          [[ $part_idx -ge 10 ]] && break
        done

        # Store to database diagnostics
        echo "[$(date -Iseconds)] Storing LVM metadata to database..." >&2
        psql_as_user "$DB_URL" -c "UPDATE medium SET diagnostics = diagnostics || E'\n\n$lvm_info' WHERE medium_hash = '$medium_hash';" 2>/dev/null || {
          echo "[$(date -Iseconds)] WARNING: Failed to store LVM metadata to database" >&2
        }

        log lvm_metadata_stored "{\"medium_hash\": \"$medium_hash\", \"lvm_partition_count\": $lvm_count}"
      fi
    else
      # No JSON output (backward compatibility)
      echo "[$(date -Iseconds)] Mount successful (no layout metadata)" >&2
      log mount_success "{\"medium_hash\": \"$medium_hash\", \"image_path\": \"$image_path\"}"
    fi
    return 0
  else
    echo "[$(date -Iseconds)] ERROR: Mount failed" >&2
    log mount_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"mount_failed\"}"
    return 2
  fi
}

stage_enum() {
  local medium_hash="$1"

  echo "[$(date -Iseconds)] STAGE: Enumeration" >&2

  # Check if already enumerated
  local inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
  if [[ $inode_count -gt 0 ]]; then
    echo "[$(date -Iseconds)] Already enumerated ($inode_count inodes), skipping" >&2
    return 1
  fi

  # Get mount point
  local mount_point="/mnt/ntt/${medium_hash}"
  if [[ ! -d "$mount_point" ]]; then
    echo "[$(date -Iseconds)] ERROR: Mount point not found: $mount_point" >&2
    log enum_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"mount_point_missing\"}"
    return 2
  fi

  # Check for mount metadata (from stage_mount)
  local mount_meta_file="/tmp/ntt-mount-meta-${medium_hash}"
  local raw_file="$RAW_ROOT/${medium_hash}.raw"

  if [[ -f "$mount_meta_file" ]]; then
    # Parse mount metadata to detect multi-partition layout
    local layout=$(jq -r '.layout' < "$mount_meta_file")

    if [[ "$layout" == "multi" ]]; then
      # Multi-partition enumeration
      echo "[$(date -Iseconds)] Multi-partition disk detected" >&2
      log enum_start "{\"medium_hash\": \"$medium_hash\", \"layout\": \"multi\"}"

      # Get partition list
      local partition_count=$(jq '.partitions | length' < "$mount_meta_file")
      echo "[$(date -Iseconds)] Enumerating $partition_count partitions" >&2

      # Enumerate each partition separately
      local temp_raws=()
      local enum_failed=false

      for ((i=0; i<partition_count; i++)); do
        local part_num=$(jq -r ".partitions[$i].num" < "$mount_meta_file")
        local part_mount=$(jq -r ".partitions[$i].mount" < "$mount_meta_file")
        local part_status=$(jq -r ".partitions[$i].status" < "$mount_meta_file")

        # Skip failed partitions
        if [[ "$part_status" != "ok" ]]; then
          echo "[$(date -Iseconds)] Skipping partition p$part_num (status: $part_status)" >&2
          continue
        fi

        # Enumerate this partition
        local part_raw="$RAW_ROOT/${medium_hash}.p${part_num}.raw"
        echo "[$(date -Iseconds)] Enumerating p$part_num: $part_mount -> $part_raw" >&2

        if ntt-enum "$part_mount" "$medium_hash" "$part_raw"; then
          temp_raws+=("$part_num:$part_raw")
          echo "[$(date -Iseconds)] Enumerated p$part_num successfully" >&2
        else
          echo "[$(date -Iseconds)] ERROR: Failed to enumerate p$part_num" >&2
          enum_failed=true
        fi
      done

      if [[ "$enum_failed" == "true" ]]; then
        echo "[$(date -Iseconds)] ERROR: Some partitions failed enumeration" >&2
        log enum_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"partition_enum_failed\"}"
        # Cleanup temp files
        for part_info in "${temp_raws[@]}"; do
          part_raw="${part_info#*:}"
          rm -f "$part_raw"
        done
        return 2
      fi

      # Merge partition .raw files with prefixes
      echo "[$(date -Iseconds)] Merging partition enumerations to $raw_file" >&2
      > "$raw_file"  # Create empty file

      for part_info in "${temp_raws[@]}"; do
        part_num="${part_info%%:*}"
        part_raw="${part_info#*:}"

        echo "[$(date -Iseconds)] Merging p$part_num..." >&2

        # No prefix needed - paths already contain partition info in mount point
        cat "$part_raw" >> "$raw_file"

        # Remove temp file
        rm -f "$part_raw"
      done

      chmod 644 "$raw_file" 2>/dev/null || true
      rm -f "$mount_meta_file"  # Cleanup metadata file

      echo "[$(date -Iseconds)] Multi-partition enumeration complete" >&2
      log enum_success "{\"medium_hash\": \"$medium_hash\", \"raw\": \"$raw_file\", \"layout\": \"multi\", \"partitions\": $partition_count}"
      return 0

    else
      # Single-partition disk (layout == "single")
      echo "[$(date -Iseconds)] Single-partition disk detected" >&2
      rm -f "$mount_meta_file"  # Cleanup metadata file
    fi
  fi

  # Single-partition enumeration (default behavior)
  echo "[$(date -Iseconds)] Running ntt-enum: $mount_point -> $raw_file" >&2
  log enum_start "{\"medium_hash\": \"$medium_hash\", \"mount\": \"$mount_point\", \"raw\": \"$raw_file\"}"

  if ntt-enum "$mount_point" "$medium_hash" "$raw_file"; then
    chmod 644 "$raw_file" 2>/dev/null || true
    log enum_success "{\"medium_hash\": \"$medium_hash\", \"raw\": \"$raw_file\"}"
    return 0
  else
    echo "[$(date -Iseconds)] ERROR: Enumeration failed" >&2
    log enum_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"enum_failed\"}"
    return 2
  fi
}

stage_load() {
  local medium_hash="$1"

  echo "[$(date -Iseconds)] STAGE: Loader" >&2

  # Check if already loaded (check inodes, not paths - paths can be orphaned)
  local inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
  if [[ $inode_count -gt 0 ]]; then
    echo "[$(date -Iseconds)] Already loaded ($inode_count inodes), skipping" >&2
    return 1
  fi

  # Check if raw file exists
  local raw_file="$RAW_ROOT/${medium_hash}.raw"
  if [[ ! -f "$raw_file" ]]; then
    echo "[$(date -Iseconds)] ERROR: Raw file not found: $raw_file" >&2
    log load_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"raw_file_missing\"}"
    return 2
  fi

  # Run loader
  echo "[$(date -Iseconds)] Running ntt-loader: $raw_file" >&2
  log load_start "{\"medium_hash\": \"$medium_hash\", \"raw\": \"$raw_file\"}"

  if "$NTT_BIN/ntt-loader" "$raw_file" "$medium_hash"; then
    # Get final inode count after loading
    local inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
    log load_success "{\"medium_hash\": \"$medium_hash\", \"inode_count\": $inode_count}"

    # Set enum_done timestamp
    psql_as_user "$DB_URL" -c "UPDATE medium SET enum_done = NOW() WHERE medium_hash = '$medium_hash';" 2>/dev/null || true

    echo "$inode_count"  # Return inode count for smart scheduling
    return 0
  else
    echo "[$(date -Iseconds)] ERROR: Loader failed" >&2
    log load_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"loader_failed\"}"
    return 2
  fi
}

stage_copy() {
  local medium_hash="$1"
  local inode_count="${2:-0}"
  local force="${3:-false}"

  echo "[$(date -Iseconds)] STAGE: Copy ($inode_count files)" >&2

  # Check if already complete
  local pending_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash' AND copied = false AND claimed_by IS NULL" 2>/dev/null || echo "0")
  if [[ $pending_count -eq 0 ]]; then
    echo "[$(date -Iseconds)] Already complete (no pending files)" >&2
    return 1
  fi

  # Smart scheduling based on inode count
  if [[ $inode_count -lt 10000 ]]; then
    # Small/medium batch: run inline with single worker
    echo "[$(date -Iseconds)] Batch (<10K files), running inline worker" >&2
    log copy_start "{\"medium_hash\": \"$medium_hash\", \"mode\": \"inline\", \"pending\": $pending_count}"

    if "$NTT_BIN/ntt-copier.py" --medium-hash "$medium_hash"; then
      log copy_success "{\"medium_hash\": \"$medium_hash\"}"
      echo "[$(date -Iseconds)] Copy stage: SUCCESS" >&2

      # Set copy_done timestamp
      psql_as_user "$DB_URL" -c "UPDATE medium SET copy_done = NOW() WHERE medium_hash = '$medium_hash';" 2>/dev/null || true

      # Check if all files are copied
      local final_pending=$(psql_as_user "$DB_URL" -tAc \
        "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash' AND copied = false AND claimed_by IS NULL" 2>/dev/null || echo "?")

      if [[ "$final_pending" == "0" ]]; then
        echo "[$(date -Iseconds)] Copy complete! All $inode_count files copied." >&2

        # Auto-run archiver
        # echo ""
        # echo -n "Create archive package? (Y/n): " >&2
        # read -r arch_response < /dev/tty
        # arch_response=${arch_response:-Y}

        # if [[ "$arch_response" =~ ^[Yy] ]]; then
          log archive_start "{\"medium_hash\": \"$medium_hash\"}"
          echo "[$(date -Iseconds)] Running archiver..." >&2

          if $force; then
            archiver_cmd="$NTT_BIN/ntt-archiver --force $medium_hash"
          else
            archiver_cmd="$NTT_BIN/ntt-archiver $medium_hash"
          fi

          if $archiver_cmd; then
            log archive_success "{\"medium_hash\": \"$medium_hash\"}"
            echo "[$(date -Iseconds)] Archive stage: SUCCESS" >&2
            return 0
          else
            echo "[$(date -Iseconds)] Archive stage: FAILED" >&2
            log archive_error "{\"medium_hash\": \"$medium_hash\"}"
            return 2
          fi
        # else
        #   echo "Skipped. Run manually: ntt-archiver $medium_hash" >&2
        #   return 0
        # fi
      else
        echo "[$(date -Iseconds)] Copy incomplete - $final_pending files remain" >&2
        return 0
      fi
    else
      echo "[$(date -Iseconds)] ERROR: Copy worker failed" >&2
      log copy_error "{\"medium_hash\": \"$medium_hash\", \"error\": \"worker_failed\"}"
      return 2
    fi

  else
    # Large batch: auto-launch parallel workers
    echo "[$(date -Iseconds)] Large batch ($inode_count files) detected" >&2
    # echo -n "Launch 16 parallel workers? (Y/n): " >&2
    # read -r response < /dev/tty  # Read from terminal (needed under sudo)
    # response=${response:-Y}

    # if [[ "$response" =~ ^[Yy] ]]; then
      log copy_start "{\"medium_hash\": \"$medium_hash\", \"mode\": \"parallel_interactive\", \"workers\": 16}"
      echo "[$(date -Iseconds)] Launching 16 workers..." >&2

      # Launch with --wait flag to block until complete
      if "$NTT_BIN/ntt-copy-workers" \
          --medium-hash "$medium_hash" \
          --workers 16 \
          --wait; then

        # Verify completion
        local final_pending=$(psql_as_user "$DB_URL" -tAc \
          "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash' AND copied = false AND claimed_by IS NULL" 2>/dev/null || echo "?")

        if [[ "$final_pending" == "0" ]]; then
          echo "[$(date -Iseconds)] Copy complete! All $inode_count files copied." >&2
          log copy_success "{\"medium_hash\": \"$medium_hash\"}"

          # Set copy_done timestamp
          psql_as_user "$DB_URL" -c "UPDATE medium SET copy_done = NOW() WHERE medium_hash = '$medium_hash';" 2>/dev/null || true

          # Auto-run archiver
          # echo ""
          # echo -n "Create archive package? (Y/n): " >&2
          # read -r arch_response < /dev/tty
          # arch_response=${arch_response:-Y}

          # if [[ "$arch_response" =~ ^[Yy] ]]; then
            log archive_start "{\"medium_hash\": \"$medium_hash\"}"
            echo "[$(date -Iseconds)] Running archiver..." >&2

            if $force; then
              archiver_cmd="$NTT_BIN/ntt-archiver --force $medium_hash"
            else
              archiver_cmd="$NTT_BIN/ntt-archiver $medium_hash"
            fi

            if $archiver_cmd; then
              log archive_success "{\"medium_hash\": \"$medium_hash\"}"
              echo "[$(date -Iseconds)] Archive stage: SUCCESS" >&2
              return 0
            else
              echo "[$(date -Iseconds)] Archive stage: FAILED" >&2
              log archive_error "{\"medium_hash\": \"$medium_hash\"}"
              return 2
            fi
          # else
          #   echo "Skipped. Run manually: ntt-archiver $medium_hash" >&2
          #   return 0
          # fi
        else
          echo "[$(date -Iseconds)] ERROR: Copy incomplete - $final_pending files remain" >&2
          log copy_incomplete "{\"medium_hash\": \"$medium_hash\", \"remaining\": $final_pending}"
          return 2
        fi
      else
        echo "[$(date -Iseconds)] ERROR: Workers failed" >&2
        log copy_error "{\"medium_hash\": \"$medium_hash\"}"
        return 2
      fi
    # else
    #   # User declined
    #   echo "Skipped. Run manually: ntt-copy-workers -m $medium_hash -w 16" >&2
    #   log copy_defer "{\"medium_hash\": \"$medium_hash\", \"mode\": \"declined\"}"
    #   return 1
    # fi
  fi
}

# ---------- database functions ----------
check_duplicate() {
  local medium_hash="$1"
  local force="$2"

  # DISABLED: Duplicate check was causing false positives
  # if ! "$force"; then
  #   EXISTS=$(psql_as_user "$DB_URL" -t -A -c "SELECT 1 FROM medium WHERE medium_hash='$medium_hash'" 2>/dev/null || echo "")
  #   if [[ -n $EXISTS ]]; then
  #     log skip "{\"reason\": \"already ingested\"}"
  #     exit 2
  #   fi
  # fi
  return 0
}

insert_medium() {
  local medium_hash="$1"
  local medium_human="$2"
  local health="${3:-false}"
  local message="${4:-}"
  local diagnostics="${5:-}"

  # Use psql parameter binding to safely handle all special characters
  psql_as_user "$DB_URL" \
    -v hash="$medium_hash" \
    -v human="$medium_human" \
    -v health="$health" \
    -v msg="$message" \
    -v diag="$diagnostics" \
<<'SQL'
INSERT INTO medium (medium_hash, medium_human, health, message, diagnostics)
VALUES (:'hash', :'human', :'health', :'msg', :'diag')
ON CONFLICT (medium_hash) DO UPDATE
SET message = EXCLUDED.message,
    diagnostics = EXCLUDED.diagnostics;
SQL
}

# ---------- (obsolete functions removed: mount_image, unmount_image, run_enum, run_loader, run_copy_workers, cleanup_image) ----------

# ---------- mode handlers ----------
handle_device_mode() {
  local dev="$1"
  local image_first="$2"
  local force="$3"
  local enum_only="$4"
  local user_message="$5"

  # Require --message for device mode
  if [[ -z "$user_message" ]]; then
    fail "Device mode requires --message flag (e.g., --message=\"old maxtor ide 300GB\")"
  fi

  # Identify device with user message
  local identify_result=$(identify_device "$dev" "$user_message")
  [[ -n "$identify_result" ]] || exit 1  # identify_device already logged error
  local medium_hash="${identify_result%%:*}"
  local temp="${identify_result#*:}"
  local medium_human="${temp%%:*}"
  local message="${temp#*:}"

  check_duplicate "$medium_hash" "$force"

  # Insert medium record NOW (before imaging) so hardware can be disconnected
  # This captures all hardware diagnostics while device is still attached
  local IMG="$IMAGE_ROOT/${medium_hash}.img"
  echo "[$(date -Iseconds)] Inserting medium record to database..." >&2
  insert_medium "$medium_hash" "$medium_human" "NULL" "$message" "$DIAGNOSTICS"
  psql_as_user "$DB_URL" -c "UPDATE medium SET image_path = '$IMG' WHERE medium_hash = '$medium_hash';" 2>/dev/null || true

  log medium_inserted "{\"medium_hash\":\"$medium_hash\",\"medium_human\":\"$medium_human\",\"timing\":\"before_imaging\"}"

  # Image the device using ntt-imager
  local MAP="$IMAGE_ROOT/${medium_hash}.map"
  echo "[$(date -Iseconds)] Starting imaging: $dev -> $IMG" >&2
  log imager_spawn "{\"img\":\"$IMG\",\"map\":\"$MAP\",\"message\":\"$message\"}"

  ntt-imager "$dev" "$IMG" "$MAP"
  local exit_code=$?

  if [[ $exit_code -eq 2 ]]; then
    fail "ntt-imager failed with error (exit code 2)"
  elif [[ $exit_code -eq 1 ]]; then
    log imager_partial "{\"medium_hash\":\"$medium_hash\",\"msg\":\"Exhausted all recovery phases, some sectors unreadable\"}"
  else
    log imager_success "{\"medium_hash\":\"$medium_hash\",\"msg\":\"100% rescued\"}"
  fi

  # Update health based on ddrescue results
  update_health_from_mapfile "$medium_hash" "$MAP"

  # Run state-based pipeline stages
  echo "[$(date -Iseconds)] === STATE-BASED PIPELINE START ===" >&2
  log pipeline_start "{\"medium_hash\": \"$medium_hash\"}"

  # STAGE 1: Mount
  if stage_mount "$medium_hash"; then
    echo "[$(date -Iseconds)] Mount stage: SUCCESS" >&2
  else
    local mount_rc=$?
    if [[ $mount_rc -eq 1 ]]; then
      echo "[$(date -Iseconds)] Mount stage: SKIPPED (already mounted)" >&2
    else
      echo "[$(date -Iseconds)] Mount stage: FAILED (cannot continue)" >&2
      log pipeline_abort "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"mount\"}"
      return 1
    fi
  fi

  # STAGE 2: Enumeration
  if stage_enum "$medium_hash"; then
    echo "[$(date -Iseconds)] Enum stage: SUCCESS" >&2
  else
    local enum_rc=$?
    if [[ $enum_rc -eq 1 ]]; then
      echo "[$(date -Iseconds)] Enum stage: SKIPPED (already enumerated)" >&2
    else
      echo "[$(date -Iseconds)] Enum stage: FAILED" >&2
      log pipeline_error "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"enum\"}"
      # Don't abort - medium is mounted, user can debug
    fi
  fi

  # Stop here if --enum-only
  if "$enum_only"; then
    echo "[$(date -Iseconds)] === PIPELINE STOPPED (--enum-only) ===" >&2
    log pipeline_stopped "{\"medium_hash\": \"$medium_hash\", \"reason\": \"enum_only_flag\"}"
    return 0
  fi

  # STAGE 3: Loader
  local inode_count=0
  if stage_load "$medium_hash"; then
    inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
    echo "[$(date -Iseconds)] Load stage: SUCCESS ($inode_count inodes)" >&2
  else
    local load_rc=$?
    if [[ $load_rc -eq 1 ]]; then
      inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
      echo "[$(date -Iseconds)] Load stage: SKIPPED (already loaded, $inode_count inodes)" >&2
    else
      echo "[$(date -Iseconds)] Load stage: FAILED" >&2
      log pipeline_error "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"load\"}"
      # Don't abort - medium is mounted, user can debug
    fi
  fi

  # STAGE 4: Copy (with smart scheduling)
  if [[ $inode_count -gt 0 ]]; then
    if stage_copy "$medium_hash" "$inode_count" "$force"; then
      echo "[$(date -Iseconds)] Copy stage: SUCCESS" >&2
    else
      local copy_rc=$?
      if [[ $copy_rc -eq 1 ]]; then
        # Check if copying is actually complete vs user declined
        local pending_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash' AND copied = false AND claimed_by IS NULL" 2>/dev/null || echo "0")
        if [[ "$pending_count" == "0" ]]; then
          echo "[$(date -Iseconds)] Copy stage: ALREADY COMPLETE" >&2
          echo "[$(date -Iseconds)] All files already copied, running archiver..." >&2

          # Auto-run archiver
          # echo ""
          # echo -n "Create archive package? (Y/n): " >&2
          # read -r arch_response < /dev/tty
          # arch_response=${arch_response:-Y}

          # if [[ "$arch_response" =~ ^[Yy] ]]; then
            log archive_start "{\"medium_hash\": \"$medium_hash\"}"
            echo "[$(date -Iseconds)] Running archiver..." >&2

            if $force; then
              archiver_cmd="$NTT_BIN/ntt-archiver --force $medium_hash"
            else
              archiver_cmd="$NTT_BIN/ntt-archiver $medium_hash"
            fi

            if $archiver_cmd; then
              log archive_success "{\"medium_hash\": \"$medium_hash\"}"
              echo "[$(date -Iseconds)] Archive stage: SUCCESS" >&2
            else
              echo "[$(date -Iseconds)] Archive stage: FAILED" >&2
              log archive_error "{\"medium_hash\": \"$medium_hash\"}"
            fi
          # else
          #   echo "Skipped. Run manually: ntt-archiver $medium_hash" >&2
          # fi
        else
          echo "[$(date -Iseconds)] Copy stage: DEFERRED (user declined)" >&2
        fi
      else
        echo "[$(date -Iseconds)] Copy stage: FAILED" >&2
        log pipeline_error "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"copy\"}"
      fi
    fi
  else
    echo "[$(date -Iseconds)] Copy stage: SKIPPED (no inodes to copy)" >&2
  fi

  echo "[$(date -Iseconds)] === PIPELINE COMPLETE ===" >&2
  log pipeline_done "{\"medium_hash\": \"$medium_hash\"}"

  # Leave image mounted for copy workers / manual inspection
  # Cleanup will be handled by ntt-cleanup-mounts periodic job
  log mount_persisted "{\"medium_hash\": \"$medium_hash\", \"note\": \"left mounted for workers or inspection\"}"
}

handle_directory_mode() {
  local path="$1"
  local force="$2"
  local enum_only="$3"

  # Identify path
  local identify_result=$(identify_path "$path")
  [[ -n "$identify_result" ]] || exit 1  # identify_path already logged error
  local medium_hash="${identify_result%%:*}"
  local medium_human="${identify_result#*:}"

  # Check if raw file already exists
  RAW="$RAW_ROOT/${medium_hash}.raw"
  if [[ -f "$RAW" ]] && ! "$force"; then
    fail "Raw file already exists: $RAW (use --force to overwrite)"
  fi

  check_duplicate "$medium_hash" "$force"

  # Insert into database (no health check for paths)
  insert_medium "$medium_hash" "$medium_human" "false"

  # Run enum directly on the path
  RAW=$(run_enum "$path" "$medium_hash")

  # Run full pipeline unless --enum-only
  if ! "$enum_only"; then
    run_loader "$medium_hash" "$RAW"
    run_copy_workers "$medium_hash"
  fi
}

handle_image_mode() {
  local image_path="$1"
  local force="$2"
  local enum_only="$3"
  local user_message="${4:-}"

  # Identify image (content-based hash) with message
  local identify_result=$(identify_image "$image_path" "$user_message")
  [[ -n "$identify_result" ]] || exit 1  # identify_image already logged error
  local medium_hash="${identify_result%%:*}"
  local temp="${identify_result#*:}"
  local medium_human="${temp%%:*}"
  local message="${temp#*:}"

  # Read image diagnostics from temp file
  if [[ -f "/tmp/ntt-image-diag-$$" ]]; then
    DIAGNOSTICS=$(cat "/tmp/ntt-image-diag-$$")
    rm -f "/tmp/ntt-image-diag-$$"
  fi

  # Check if raw file already exists
  RAW="$RAW_ROOT/${medium_hash}.raw"
  if [[ -f "$RAW" ]] && ! "$force"; then
    fail "Raw file already exists: $RAW (use --force to overwrite)"
  fi

  check_duplicate "$medium_hash" "$force"

  # Insert medium record NOW with image_path (so stage_mount can find it)
  echo "[$(date -Iseconds)] Inserting medium record to database..." >&2
  insert_medium "$medium_hash" "$medium_human" "ok" "$message" "$DIAGNOSTICS"
  psql_as_user "$DB_URL" -c "UPDATE medium SET image_path = '$image_path' WHERE medium_hash = '$medium_hash';" 2>/dev/null || true

  log medium_inserted "{\"medium_hash\":\"$medium_hash\",\"medium_human\":\"$medium_human\",\"mode\":\"image\"}"

  # Run state-based pipeline stages
  echo "[$(date -Iseconds)] === STATE-BASED PIPELINE START ===" >&2
  log pipeline_start "{\"medium_hash\": \"$medium_hash\", \"mode\": \"image\"}"

  # STAGE 1: Mount (uses ntt-mount-helper with partition support)
  if stage_mount "$medium_hash"; then
    echo "[$(date -Iseconds)] Mount stage: SUCCESS" >&2
  else
    local mount_rc=$?
    if [[ $mount_rc -eq 1 ]]; then
      echo "[$(date -Iseconds)] Mount stage: SKIPPED (already mounted)" >&2
    else
      echo "[$(date -Iseconds)] Mount stage: FAILED (cannot continue)" >&2
      log pipeline_abort "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"mount\"}"
      return 1
    fi
  fi

  # STAGE 2: Enumeration (handles multi-partition)
  if stage_enum "$medium_hash"; then
    echo "[$(date -Iseconds)] Enum stage: SUCCESS" >&2
  else
    local enum_rc=$?
    if [[ $enum_rc -eq 1 ]]; then
      echo "[$(date -Iseconds)] Enum stage: SKIPPED (already enumerated)" >&2
    else
      echo "[$(date -Iseconds)] Enum stage: FAILED" >&2
      log pipeline_error "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"enum\"}"
      # Don't abort - medium is mounted, user can debug
    fi
  fi

  # Stop here if --enum-only
  if "$enum_only"; then
    echo "[$(date -Iseconds)] === PIPELINE STOPPED (--enum-only) ===" >&2
    log pipeline_stopped "{\"medium_hash\": \"$medium_hash\", \"reason\": \"enum_only_flag\"}"
    return 0
  fi

  # STAGE 3: Loader
  local inode_count=0
  if stage_load "$medium_hash"; then
    inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
    echo "[$(date -Iseconds)] Load stage: SUCCESS ($inode_count inodes)" >&2
  else
    local load_rc=$?
    if [[ $load_rc -eq 1 ]]; then
      inode_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash'" 2>/dev/null || echo "0")
      echo "[$(date -Iseconds)] Load stage: SKIPPED (already loaded, $inode_count inodes)" >&2
    else
      echo "[$(date -Iseconds)] Load stage: FAILED" >&2
      log pipeline_error "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"load\"}"
      # Don't abort - medium is mounted, user can debug
    fi
  fi

  # STAGE 4: Copy (with smart scheduling)
  if [[ $inode_count -gt 0 ]]; then
    if stage_copy "$medium_hash" "$inode_count" "$force"; then
      echo "[$(date -Iseconds)] Copy stage: SUCCESS" >&2
    else
      local copy_rc=$?
      if [[ $copy_rc -eq 1 ]]; then
        # Check if copying is actually complete vs user declined
        local pending_count=$(psql_as_user "$DB_URL" -tAc "SELECT COUNT(*) FROM inode WHERE medium_hash = '$medium_hash' AND copied = false AND claimed_by IS NULL" 2>/dev/null || echo "0")
        if [[ "$pending_count" == "0" ]]; then
          echo "[$(date -Iseconds)] Copy stage: ALREADY COMPLETE" >&2
          echo "[$(date -Iseconds)] All files already copied, running archiver..." >&2

          # Auto-run archiver
          # echo ""
          # echo -n "Create archive package? (Y/n): " >&2
          # read -r arch_response < /dev/tty
          # arch_response=${arch_response:-Y}

          # if [[ "$arch_response" =~ ^[Yy] ]]; then
            log archive_start "{\"medium_hash\": \"$medium_hash\"}"
            echo "[$(date -Iseconds)] Running archiver..." >&2

            if $force; then
              archiver_cmd="$NTT_BIN/ntt-archiver --force $medium_hash"
            else
              archiver_cmd="$NTT_BIN/ntt-archiver $medium_hash"
            fi

            if $archiver_cmd; then
              log archive_success "{\"medium_hash\": \"$medium_hash\"}"
              echo "[$(date -Iseconds)] Archive stage: SUCCESS" >&2
            else
              echo "[$(date -Iseconds)] Archive stage: FAILED" >&2
              log archive_error "{\"medium_hash\": \"$medium_hash\"}"
            fi
          # else
          #   echo "Skipped. Run manually: ntt-archiver $medium_hash" >&2
          # fi
        else
          echo "[$(date -Iseconds)] Copy stage: DEFERRED (user declined)" >&2
        fi
      else
        echo "[$(date -Iseconds)] Copy stage: FAILED" >&2
        log pipeline_error "{\"medium_hash\": \"$medium_hash\", \"failed_stage\": \"copy\"}"
      fi
    fi
  else
    echo "[$(date -Iseconds)] Copy stage: SKIPPED (no inodes to copy)" >&2
  fi

  echo "[$(date -Iseconds)] === PIPELINE COMPLETE ===" >&2
  log pipeline_done "{\"medium_hash\": \"$medium_hash\", \"mode\": \"image\"}"

  # Leave image mounted for copy workers / manual inspection
  # Cleanup will be handled by ntt-cleanup-mounts periodic job
  log mount_persisted "{\"medium_hash\": \"$medium_hash\", \"note\": \"left mounted for workers or inspection\"}"
}

# ---------- load-only mode handler ----------
handle_load_only_mode() {
  local raw_file="$1"

  # Check if raw file exists
  if [[ ! -f "$raw_file" ]]; then
    fail "Raw file not found: $raw_file"
  fi

  # Extract medium_hash from filename (remove path and .raw extension)
  local filename=$(basename "$raw_file")
  local medium_hash="${filename%.raw}"

  # Validate it looks like a hash
  if [[ ! "$medium_hash" =~ ^[a-f0-9]{16,64}$ ]]; then
    fail "Invalid filename format: expected hash.raw, got $filename"
  fi

  echo "[$(date -Iseconds)] Loading raw file: $raw_file (medium_hash: $medium_hash)" >&2
  log load_only_start "{\"raw_file\": \"$raw_file\", \"medium_hash\": \"$medium_hash\"}"

  # Run loader directly (no enum, no copy workers)
  "$NTT_BIN/ntt-loader" "$raw_file" "$medium_hash"

  log load_only_done "{\"medium_hash\": \"$medium_hash\", \"exit\": 0}"
}

# ---------- argparse ----------
usage() {
  cat <<EOF
Usage:
  sudo $0 [--enum-only] [--force] /dev/sdX                # Device enumeration (PARTIAL)
  sudo $0 [--enum-only] [--force] /path/to/directory      # Directory enumeration
  sudo $0 [--enum-only] [--force] --image /path/to/image  # Disk image enumeration
  sudo $0 --load-only /path/to/file.raw                   # Load .raw into database

Current implementation status:
  ❌ TODO: Device imaging, mounting, health checks
  ✅ WORKING: Directory enumeration → .raw files → PostgreSQL loading
  ✅ WORKING: Disk image processing (content-based hash, auto mount/unmount)
  ✅ WORKING: .raw file loading into database
  ❌ TODO: Copy workers (file copying/deduplication)

Modes:
  /path/to/dir    Enumerate directory, optionally load to database
  /dev/sdX        Enumerate device (basic - no imaging/mounting yet)
  --image FILE    Process disk image (auto mount/unmount, content-based hash)
  --load-only     Load existing .raw file into PostgreSQL

Options:
  --enum-only     Stop after enumeration (.raw file creation)
  --force         Bypass duplicate checking
  --load-only     Load mode: process existing .raw file
  --image FILE    Image mode: process disk image file

Examples:
  sudo $0 --image /data/fast/img/tm-20140409-partition3.img
  sudo $0 --image /data/fast/img/partition3.img --enum-only
  sudo $0 --force --image /path/to/image.img
EOF
  exit 1
}

# Parse arguments
[[ $# -ge 1 ]] || usage

# Initialize flags
LOAD_ONLY_MODE=false
IMAGE_MODE=false
IMAGE_FIRST=false
FORCE=false
ENUM_ONLY=false
TARGET=""
LOAD_ONLY_FILE=""
IMAGE_FILE=""
USER_MESSAGE=""

# Parse options first
while [[ $# -gt 0 ]]; do
  case $1 in
    --load-only)
      LOAD_ONLY_MODE=true
      shift
      # Next argument should be the .raw file
      if [[ $# -eq 1 ]]; then
        LOAD_ONLY_FILE="$1"
        shift
      else
        usage
      fi
      ;;
    --image)
      IMAGE_MODE=true
      shift
      # Next argument should be the image file
      if [[ $# -ge 1 && "$1" != -* ]]; then
        IMAGE_FILE="$1"
        shift
      else
        echo "Error: --image requires an image file path" >&2
        usage
      fi
      ;;
    --image-first)
      IMAGE_FIRST=true
      shift
      ;;
    --message)
      shift
      if [[ $# -ge 1 && "$1" != -* ]]; then
        USER_MESSAGE="$1"
        shift
      else
        echo "Error: --message requires a description string" >&2
        usage
      fi
      ;;
    --force)
      FORCE=true
      shift
      ;;
    --enum-only)
      ENUM_ONLY=true
      shift
      ;;
    -*)
      echo "Unknown option: $1" >&2
      usage
      ;;
    *)
      # First non-option argument is the target
      if [[ -z "$TARGET" && "$LOAD_ONLY_MODE" == false && "$IMAGE_MODE" == false ]]; then
        TARGET="$1"
        shift
        break  # Stop parsing after target is set
      else
        # Extra arguments not allowed
        usage
      fi
      ;;
  esac
done

# Check for extra arguments after target
if [[ $# -gt 0 ]]; then
  echo "Extra arguments not allowed after target: $@" >&2
  usage
fi

# Validate arguments
if [[ "$LOAD_ONLY_MODE" == true ]]; then
  [[ -n "$LOAD_ONLY_FILE" ]] || usage
elif [[ "$IMAGE_MODE" == true ]]; then
  [[ -n "$IMAGE_FILE" ]] || usage
else
  [[ -n "$TARGET" ]] || usage
fi

# Resolve IMAGE_FILE prefix to full path if needed
if [[ "$IMAGE_MODE" == true ]]; then
  if [[ ! -f "$IMAGE_FILE" ]]; then
    # Check if it looks like a hash prefix (with or without extension)
    filename=$(basename "$IMAGE_FILE")
    base="${filename%.*}"  # Strip extension if present

    if [[ "$base" =~ ^[a-f0-9]{8,31}$ ]]; then
      # Looks like a hash prefix - search for matching files in IMAGE_ROOT
      matches=("$IMAGE_ROOT"/${base}*.img)

      # Check if glob found real files (not literal pattern)
      if [[ -f "${matches[0]}" ]]; then
        if [[ ${#matches[@]} -eq 1 ]]; then
          echo "[$(date -Iseconds)] Resolved hash prefix: $base -> ${matches[0]}" >&2
          IMAGE_FILE="${matches[0]}"
        else
          echo "Error: Ambiguous hash prefix '$base', multiple matches:" >&2
          printf '  %s\n' "${matches[@]}" >&2
          exit 1
        fi
      # else: no matches, let identify_image() handle the "not found" error
      fi
    # else: not a hash pattern, let identify_image() handle it
    fi
  fi
fi

# ---------- main ----------
if [[ "$LOAD_ONLY_MODE" == "true" ]]; then
  handle_load_only_mode "$LOAD_ONLY_FILE"
elif [[ "$IMAGE_MODE" == "true" ]]; then
  handle_image_mode "$IMAGE_FILE" "$FORCE" "$ENUM_ONLY" "$USER_MESSAGE"
elif [[ "$TARGET" == /dev/* ]]; then
  handle_device_mode "$TARGET" "$IMAGE_FIRST" "$FORCE" "$ENUM_ONLY" "$USER_MESSAGE"
else
  handle_directory_mode "$TARGET" "$FORCE" "$ENUM_ONLY"
fi

log done "{\"exit\": 0}"
exit 0
