#!/usr/bin/env bash
# Author: PB, Claude, and Kimi
# Date: 2025-01-02
# License: (c) HRDAG, 2025, GPL-2 or newer
#
# ------
# ntt/bin/ntt-loader
#
# NTT loader – streaming .raw (034/NUL) → Postgres
set -euo pipefail

FILE=${1:?file.raw required}
MEDIUM_HASH=${2:?medium_hash required}
DB_URL=${NTT_DB_URL:-postgres:///copyjob}
LOG_JSON=${NTT_LOADER_LOG:-/var/log/ntt/loader.jsonl}
ENUM_LOG=${NTT_ENUM_LOG:-/var/log/ntt/enum.jsonl}

mkdir -p "$(dirname "$LOG_JSON")"
chmod 755 "$(dirname "$LOG_JSON")" 2>/dev/null || true

# ---------- logging functions ----------
log() {
  jq -cn --arg ts "$(date -Iseconds)" \
        --arg stage "$1" \
        --argjson extra "$2" \
        '$extra + {ts: $ts, stage: $stage}' \
  >> "$LOG_JSON"
  chmod 644 "$LOG_JSON" 2>/dev/null || true
}

fail() {
  echo "Error: $1" >&2
  log error "{\"msg\": \"$1\"}"
  exit 1
}

# ---------- 1. create working table ----------
TABLE_NAME="tmp_path_$$"
echo "[$(date -Iseconds)] Creating working table..." >&2
log start "{\"file\": \"$FILE\", \"medium_hash\": \"$MEDIUM_HASH\"}"

# Create temp table that matches raw file format
TEMP_TABLE="raw_$$"
sudo -u "${SUDO_USER:-$USER}" psql "$DB_URL" -c "
CREATE TABLE $TEMP_TABLE (
  mode        text,
  dev         bigint,
  ino         bigint,
  nlink       int,
  size        bigint,
  mtime       bigint,
  path        text
);

CREATE TABLE $TABLE_NAME (
  medium_hash text,
  dev         bigint,
  ino         bigint,
  nlink       int,
  size        bigint,
  mtime       numeric,
  path        text
);
" || fail "Failed to create working tables"

# ---------- 2. raw → working table (034 delimiter) ----------
echo "[$(date -Iseconds)] Loading raw data into working table..." >&2
log load_start "{\"file\": \"$FILE\"}"

# Get expected record count from enum log instead of re-counting
EXPECTED_RECORDS=$(jq -rs --arg file "$FILE" '
  map(select(.stage == "enum_complete" and .out == $file)) |
  sort_by(.ts) | last | .rows // "unknown"
' "$ENUM_LOG")
echo "[$(date -Iseconds)] Expecting $EXPECTED_RECORDS records (from enum log)..." >&2

# Ultra-safe CRLF check using Perl (more reliable than grep)
if perl -n0777 -e 'exit 1 if /\r\n/' "$FILE"; then
  echo "[$(date -Iseconds)] ✓ No CRLF sequences found in raw file" >&2
else
  fail "Raw file contains CRLF sequences - cannot use CRLF as record delimiter"
fi

# Convert null to CRLF - less likely to appear in filenames than single LF
COPY_RESULT=$(sed 's/\x00/\r\n/g' < "$FILE" | sudo -u "${SUDO_USER:-$USER}" psql "$DB_URL" -c "
COPY $TEMP_TABLE(mode,dev,ino,nlink,size,mtime,path)
FROM STDIN
WITH (FORMAT text, DELIMITER E'\\034', NULL '');
" 2>&1) || fail "Failed to load raw data into temp table"

# Extract actual imported count from PostgreSQL output
ACTUAL_RECORDS=$(echo "$COPY_RESULT" | grep "COPY" | grep -o '[0-9]*' | tail -1)
echo "[$(date -Iseconds)] PostgreSQL imported $ACTUAL_RECORDS records" >&2

# Sanity check: compare expected vs actual
if [[ "$EXPECTED_RECORDS" != "$ACTUAL_RECORDS" ]]; then
  echo "WARNING: Record count mismatch! Expected: $EXPECTED_RECORDS, Actual: $ACTUAL_RECORDS" >&2
  log warning "{\"expected\": $EXPECTED_RECORDS, \"actual\": $ACTUAL_RECORDS, \"msg\": \"record_count_mismatch\"}"
fi

# Transfer data to working table with medium_hash
sudo -u "${SUDO_USER:-$USER}" psql "$DB_URL" -c "
INSERT INTO $TABLE_NAME (medium_hash,dev,ino,nlink,size,mtime,path)
SELECT '$MEDIUM_HASH', dev, ino, nlink, size, mtime, path
FROM $TEMP_TABLE;
" || fail "Failed to transfer data to working table"

# ---------- 3. dedupe into real tables ----------
echo "[$(date -Iseconds)] Deduplicating into final tables..." >&2
log dedupe_start "{\"medium_hash\": \"$MEDIUM_HASH\"}"

sudo -u "${SUDO_USER:-$USER}" psql "$DB_URL" -c "
-- medium row (if new)
INSERT INTO medium (medium_hash, added_at)
SELECT DISTINCT medium_hash, now()
FROM   $TABLE_NAME
ON CONFLICT DO NOTHING;

-- inode rows (unique by medium_hash,dev,ino)
INSERT INTO inode (medium_hash,dev,ino,nlink,size,mtime)
SELECT medium_hash,dev,ino,MAX(nlink),MAX(size),MAX(mtime)
FROM   $TABLE_NAME
GROUP  BY medium_hash,dev,ino
ON CONFLICT (medium_hash,dev,ino) DO NOTHING;

-- path rows (unique by full path)
INSERT INTO path (medium_hash,dev,ino,path)
SELECT medium_hash,dev,ino,path
FROM   $TABLE_NAME
ON CONFLICT (medium_hash,dev,ino,path) DO NOTHING;
" || fail "Failed to deduplicate into final tables"

# ---------- 4. cleanup and summary ----------
ROWS=$(sudo -u "${SUDO_USER:-$USER}" psql "$DB_URL" -t -A -c "SELECT count(*) FROM path WHERE medium_hash='$MEDIUM_HASH'" 2>/dev/null | grep -o '[0-9]*' | head -1 || echo "unknown")

# Drop the working tables
sudo -u "${SUDO_USER:-$USER}" psql "$DB_URL" -c "DROP TABLE $TABLE_NAME, $TEMP_TABLE;" 2>/dev/null || true
if [[ "$ACTUAL_RECORDS" == "0" ]]; then
  echo "[$(date -Iseconds)] ✓ Loading complete: $ROWS paths total for medium $MEDIUM_HASH (no new records - already loaded)" >&2
else
  echo "[$(date -Iseconds)] ✓ Loading complete: $ROWS paths loaded for medium $MEDIUM_HASH" >&2
fi
log done "{\"rows\": \"$ROWS\", \"exit\": 0}"

exit 0
