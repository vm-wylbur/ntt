#!/usr/bin/env bash
# Author: PB and Claude
# Date: 2025-10-05
# License: (c) HRDAG, 2025, GPL-2 or newer
#
# ------
# ntt/bin/ntt-mount-helper
#
# Sudo wrapper for mounting/unmounting NTT disk images
# Validates inputs and uses standard mount paths

set -euo pipefail

usage() {
  cat <<EOF
Usage:
  $0 mount <medium_hash> <image_path>    Mount image to /mnt/ntt/<medium_hash>
  $0 unmount <medium_hash>               Unmount and detach loop device
  $0 status <medium_hash>                Check if mounted (exit 0=yes, 1=no)

Security:
  - Only mounts to /mnt/ntt/<hash> (no arbitrary paths)
  - Validates medium_hash format (hex only)
  - Read-only mounts with nosuid,nodev,noatime
EOF
  exit 1
}

# Validate medium hash (32-64 hex chars)
validate_hash() {
  local hash="$1"
  if [[ ! "$hash" =~ ^[a-f0-9]{16,64}$ ]]; then
    echo "Error: Invalid medium_hash format (must be 16-64 hex chars)" >&2
    exit 1
  fi
}

# Assemble RAID array from partition device
# Returns md device path on success, empty string on failure
assemble_raid_array() {
  local part_dev="$1"
  local part_num="$2"

  # Check if mdadm is available
  if ! command -v mdadm >/dev/null 2>&1; then
    echo "  Warning: mdadm not found, cannot assemble RAID arrays" >&2
    return 1
  fi

  # Examine RAID metadata
  local raid_info
  raid_info=$(mdadm --examine "$part_dev" 2>/dev/null)
  if [[ -z "$raid_info" ]]; then
    echo "  Warning: No valid RAID metadata on $part_dev" >&2
    return 1
  fi

  # Extract UUID for array identification
  local raid_uuid
  raid_uuid=$(echo "$raid_info" | grep "Array UUID" | awk '{print $4}')

  # Check if array is already assembled
  local existing_md
  existing_md=$(mdadm --detail --scan 2>/dev/null | grep "$raid_uuid" | awk '{print $2}' | head -1)
  if [[ -n "$existing_md" ]]; then
    echo "  RAID array already assembled: $existing_md" >&2
    echo "$existing_md"
    return 0
  fi

  # Assemble array (read-only, run mode)
  # --run forces assembly even if degraded (single-device RAID1)
  local md_device
  md_device=$(mdadm --assemble --readonly --run --uuid="$raid_uuid" "$part_dev" 2>&1 | grep -o '/dev/md[0-9]*' | head -1)

  if [[ -n "$md_device" ]]; then
    echo "  Assembled RAID array: $md_device from $part_dev" >&2
    # Wait for device to be ready
    sleep 0.2
    echo "$md_device"
    return 0
  else
    echo "  Failed to assemble RAID from $part_dev" >&2
    return 1
  fi
}

# Stop all RAID arrays associated with a mount point
stop_raid_arrays() {
  local mount_point="$1"

  # Find all md devices mounted under this mount point
  local md_devices=()
  while IFS= read -r md_dev; do
    md_devices+=("$md_dev")
  done < <(findmnt -rn -o SOURCE | grep "^/dev/md" | sort -u)

  # Check each md device to see if it's mounted under our mount point
  for md_dev in "${md_devices[@]}"; do
    local md_mount
    md_mount=$(findmnt -n -o TARGET -S "$md_dev" 2>/dev/null || echo "")

    if [[ "$md_mount" =~ ^$mount_point ]]; then
      echo "  Stopping RAID array: $md_dev" >&2
      # mdadm --stop will fail if array is still mounted, which is fine
      # (we unmount first, then stop the array)
      if mdadm --stop "$md_dev" 2>/dev/null; then
        echo "  Stopped $md_dev" >&2
      else
        echo "  Warning: Could not stop $md_dev (may still be in use)" >&2
      fi
    fi
  done
}

# Cleanup stale loop devices pointing to deleted inodes
cleanup_stale_loops() {
  local medium_hash="$1"
  local image_path="$2"
  local mount_point="/mnt/ntt/$medium_hash"

  # Find all loop devices for this image (including deleted inodes)
  # Format: /dev/loop29  0  0  0  1  /data/fast/img/HASH.img (deleted)  0  512
  local matching_loops
  matching_loops=$(losetup -l | grep "$(basename "$image_path")" || true)

  if [[ -n "$matching_loops" ]]; then
    echo "$matching_loops" | while read -r line; do
      local loop_dev=$(echo "$line" | awk '{print $1}')
      local status=$(echo "$line" | grep -o "(deleted)" || echo "")

      # Only cleanup deleted inodes (active image is fine)
      if [[ -n "$status" ]]; then
        echo "Cleaning up stale loop device: $loop_dev (deleted inode)" >&2

        # Try to unmount if it's mounted at our mount point
        if findmnt -S "$loop_dev" "$mount_point" >/dev/null 2>&1; then
          echo "  Unmounting $loop_dev from $mount_point" >&2
          umount "$mount_point" 2>/dev/null || echo "  Warning: umount failed" >&2
        fi

        # Detach loop device
        if losetup -d "$loop_dev" 2>/dev/null; then
          echo "  Detached $loop_dev" >&2
        else
          echo "  Warning: Could not detach $loop_dev (may be in use)" >&2
        fi
      fi
    done
  fi
}

# Mount command
do_mount() {
  local medium_hash="$1"
  local image_path="$2"

  validate_hash "$medium_hash"

  if [[ ! -f "$image_path" ]]; then
    echo "Error: Image file not found: $image_path" >&2
    exit 1
  fi

  local mount_point="/mnt/ntt/$medium_hash"

  # Check if already mounted
  if findmnt "$mount_point" >/dev/null 2>&1; then
    echo "Already mounted at $mount_point"
    exit 0
  fi

  # Cleanup stale loop devices before mounting
  cleanup_stale_loops "$medium_hash" "$image_path"

  # Create mount point
  mkdir -p "$mount_point"

  # Create loop device (read-only, with partition scanning)
  local loop_device
  loop_device=$(losetup -f --show -r -P "$image_path")
  if [[ -z "$loop_device" ]]; then
    rmdir "$mount_point" 2>/dev/null || true
    echo "Error: Failed to create loop device for $image_path" >&2
    exit 1
  fi

  # Wait briefly for kernel to create partition devices
  sleep 0.2

  # Check for partition devices (multi-partition disk)
  local partition_devices=()
  local has_partitions=false

  # Explicitly find partition devices
  while IFS= read -r part_dev; do
    partition_devices+=("$part_dev")
    has_partitions=true
  done < <(ls "${loop_device}"p* 2>/dev/null || true)

  if [[ "$has_partitions" == "true" ]]; then
    # Multi-partition disk - mount each partition to subdirectory
    echo "Multi-partition disk detected" >&2

    # First, scan for and assemble ALL RAID arrays on this disk
    # This handles RAID partitions that don't show TYPE="linux_raid_member" in blkid
    if command -v mdadm >/dev/null 2>&1; then
      # Load RAID1 kernel module if not already loaded
      modprobe raid1 2>/dev/null || true

      # Scan and assemble all RAID arrays found on these partitions
      echo "Scanning for RAID arrays..." >&2
      # Try non-degraded first, then force start with --run (for single-device RAID1)
      mdadm --assemble --scan --no-degraded 2>/dev/null || true
      mdadm --assemble --scan --run 2>/dev/null || true
    fi

    local partition_count=0
    local mounted_partitions=()

    for part_dev in "${partition_devices[@]}"; do
      # Extract partition number (e.g., /dev/loop0p1 â†’ 1)
      local part_num="${part_dev##*p}"

      # Skip extended partition containers (blkid returns PTTYPE instead of TYPE)
      local part_type
      part_type=$(blkid -o value -s TYPE "$part_dev" 2>/dev/null || echo "")
      if [[ -z "$part_type" ]]; then
        echo "  Skipping $part_dev (extended partition container)" >&2
        continue
      fi

      # Skip RAID members - they're handled by mdadm --scan above
      # The resulting md devices will be mounted later
      if [[ "$part_type" == "linux_raid_member" ]]; then
        echo "  Skipping $part_dev (RAID member, will mount assembled array)" >&2
        continue
      fi

      # Create partition mount point
      local part_mount="$mount_point/p$part_num"
      mkdir -p "$part_mount"

      # Try to mount this partition
      if mount -t "$part_type" -o ro,noatime,nodev,nosuid "$part_dev" "$part_mount" 2>/dev/null; then
        echo "  Mounted $part_dev at $part_mount (fs_type: $part_type)" >&2
        mounted_partitions+=("$part_num:$part_dev:$part_mount:$part_type:ok")
        partition_count=$((partition_count + 1))
      else
        echo "  Failed to mount $part_dev" >&2
        rmdir "$part_mount" 2>/dev/null || true
        mounted_partitions+=("$part_num:$part_dev::$part_type:failed")
      fi
    done

    # After trying partitions, also check for assembled RAID devices
    # mdadm --scan may have assembled arrays that weren't detected per-partition
    if command -v mdadm >/dev/null 2>&1; then
      local seen_md_devices=()

      for md_dev in /dev/md[0-9]* /dev/md/*; do
        [[ -b "$md_dev" ]] || [[ -L "$md_dev" && -b "$(readlink -f "$md_dev")" ]] || continue
        # Resolve symlinks
        md_dev=$(readlink -f "$md_dev")

        # Skip if already processed (dedup /dev/md5 and /dev/md/5)
        local already_seen=false
        for seen in "${seen_md_devices[@]}"; do
          if [[ "$seen" == "$md_dev" ]]; then
            already_seen=true
            break
          fi
        done
        [[ "$already_seen" == "true" ]] && continue
        seen_md_devices+=("$md_dev")

        # Skip if already mounted (might have been mounted in partition loop)
        local already_mounted=false
        for part_info in "${mounted_partitions[@]}"; do
          IFS=':' read -r num dev mnt fstype status <<< "$part_info"
          if [[ "$dev" == "$md_dev" ]]; then
            already_mounted=true
            break
          fi
        done
        [[ "$already_mounted" == "true" ]] && continue

        # Get filesystem type
        local md_fs_type
        md_fs_type=$(blkid -o value -s TYPE "$md_dev" 2>/dev/null || echo "")
        [[ -n "$md_fs_type" ]] || continue

        # Find a partition number to use (use next available)
        local md_part_num=$((partition_count + 1))

        # Create mount point
        local md_mount="$mount_point/p$md_part_num"
        mkdir -p "$md_mount"

        # Try to mount
        if mount -t "$md_fs_type" -o ro,noatime,nodev,nosuid "$md_dev" "$md_mount" 2>/dev/null; then
          echo "  Mounted $md_dev at $md_mount (RAID, fs_type: $md_fs_type)" >&2
          mounted_partitions+=("$md_part_num:$md_dev:$md_mount:$md_fs_type:ok")
          partition_count=$((partition_count + 1))
        else
          echo "  Failed to mount $md_dev" >&2
          rmdir "$md_mount" 2>/dev/null || true
        fi
      done
    fi

    if [[ $partition_count -eq 0 ]]; then
      # No partitions mounted successfully - cleanup any assembled RAID arrays
      stop_raid_arrays "$mount_point"
      losetup -d "$loop_device" 2>/dev/null || true
      rmdir "$mount_point" 2>/dev/null || true
      echo "Error: No partitions could be mounted" >&2
      exit 1
    fi

    # Output JSON for orchestrator
    echo '{"layout":"multi","partitions":['
    local first=true
    for part_info in "${mounted_partitions[@]}"; do
      IFS=':' read -r num dev mnt fstype status <<< "$part_info"
      [[ "$first" == "true" ]] || echo ','
      first=false
      echo -n "{\"num\":$num,\"device\":\"$dev\",\"mount\":\"$mnt\",\"fstype\":\"$fstype\",\"status\":\"$status\"}"
    done
    echo ']}'

    exit 0
  else
    # Single-partition or whole-disk filesystem
    echo "Single-partition disk detected" >&2
    local fs_type
    fs_type=$(blkid -o value -s TYPE "$loop_device" 2>/dev/null || echo "")

    # Mount with detected filesystem type (or auto-detect)
    if [[ -n "$fs_type" ]]; then
      if mount -t "$fs_type" -o ro,noatime,nodev,nosuid "$loop_device" "$mount_point" 2>/dev/null; then
        echo "Mounted $loop_device at $mount_point (fs_type: $fs_type)" >&2
        echo '{"layout":"single","device":"'"$loop_device"'","mount":"'"$mount_point"'","fstype":"'"$fs_type"'"}'
        exit 0
      fi
    fi

    # Fallback: try auto-detect
    if mount -o ro,noatime,nodev,nosuid "$loop_device" "$mount_point" 2>/dev/null; then
      echo "Mounted $loop_device at $mount_point (auto-detected fs_type)" >&2
      echo '{"layout":"single","device":"'"$loop_device"'","mount":"'"$mount_point"'","fstype":"auto"}'
      exit 0
    fi

    # Optical media fallback: ISO9660/UDF bridge format
    # Many optical discs report "udf" via blkid but mount as "iso9660" (or vice versa)
    if [[ "$fs_type" == "udf" ]]; then
      echo "UDF mount failed, trying ISO9660 (common for bridge-format optical discs)..." >&2
      if mount -t iso9660 -o ro,noatime,nodev,nosuid "$loop_device" "$mount_point" 2>/dev/null; then
        echo "Mounted $loop_device at $mount_point (fs_type: iso9660)" >&2
        echo '{"layout":"single","device":"'"$loop_device"'","mount":"'"$mount_point"'","fstype":"iso9660"}'
        exit 0
      fi
    elif [[ "$fs_type" == "iso9660" ]]; then
      echo "ISO9660 mount failed, trying UDF..." >&2
      if mount -t udf -o ro,noatime,nodev,nosuid "$loop_device" "$mount_point" 2>/dev/null; then
        echo "Mounted $loop_device at $mount_point (fs_type: udf)" >&2
        echo '{"layout":"single","device":"'"$loop_device"'","mount":"'"$mount_point"'","fstype":"udf"}'
        exit 0
      fi
    fi

    # Zip disk special case: filesystem may start at offset 16384 bytes (sector 32)
    # Zip disks (100MB/250MB/750MB Iomega removable media) often have FAT16/FAT32
    # filesystems starting at 0x4000 instead of sector 0
    echo "Standard mount failed, trying Zip disk offset (16384 bytes)..." >&2

    # Create offset loop device (mount doesn't support offset= for loop devices)
    local zip_loop_device
    zip_loop_device=$(losetup -f --show -r -o 16384 "$image_path" 2>/dev/null)

    if [[ -n "$zip_loop_device" ]]; then
      # Wait for device to be ready
      sleep 0.1

      # Detect filesystem type at offset
      local zip_fs_type
      zip_fs_type=$(blkid -o value -s TYPE "$zip_loop_device" 2>/dev/null || echo "")

      # Try mounting with detected type or auto-detect
      local mount_success=false
      if [[ -n "$zip_fs_type" ]]; then
        if mount -t "$zip_fs_type" -o ro,noatime,nodev,nosuid "$zip_loop_device" "$mount_point" 2>/dev/null; then
          echo "Mounted $zip_loop_device at $mount_point (Zip disk offset=16384, fs_type=$zip_fs_type)" >&2
          echo '{"layout":"single","device":"'"$zip_loop_device"'","mount":"'"$mount_point"'","fstype":"'"$zip_fs_type"'","offset":16384}'
          mount_success=true
        fi
      fi

      # Fallback: try auto-detect
      if [[ "$mount_success" == "false" ]]; then
        if mount -o ro,noatime,nodev,nosuid "$zip_loop_device" "$mount_point" 2>/dev/null; then
          echo "Mounted $zip_loop_device at $mount_point (Zip disk offset=16384, auto-detected)" >&2
          echo '{"layout":"single","device":"'"$zip_loop_device"'","mount":"'"$mount_point"'","fstype":"auto","offset":16384}'
          mount_success=true
        fi
      fi

      if [[ "$mount_success" == "true" ]]; then
        # Successfully mounted - detach original loop device (offset device is now in use)
        losetup -d "$loop_device" 2>/dev/null || true
        exit 0
      else
        # Mount failed - cleanup offset device
        losetup -d "$zip_loop_device" 2>/dev/null || true
        echo "Failed to mount Zip disk at offset 16384 (fs_type: ${zip_fs_type:-unknown})" >&2
      fi
    fi

    # Mount failed - cleanup
    losetup -d "$loop_device" 2>/dev/null || true
    rmdir "$mount_point" 2>/dev/null || true
    echo "Error: Failed to mount $loop_device" >&2
    exit 1
  fi
}

# Unmount command
do_unmount() {
  local medium_hash="$1"

  validate_hash "$medium_hash"

  local mount_point="/mnt/ntt/$medium_hash"

  # Check if base mount point exists
  if [[ ! -d "$mount_point" ]]; then
    echo "Not mounted: $mount_point (directory does not exist)"
    exit 0
  fi

  # Detect if this is a multi-partition mount (has p{N} subdirectories)
  local partition_mounts=("$mount_point"/p*)
  local has_partition_mounts=false
  local loop_device=""

  if [[ -d "${partition_mounts[0]}" ]]; then
    has_partition_mounts=true
  fi

  if [[ "$has_partition_mounts" == "true" ]]; then
    # Multi-partition disk - unmount each partition
    echo "Multi-partition disk detected, unmounting all partitions" >&2

    for part_mount in "${partition_mounts[@]}"; do
      if findmnt "$part_mount" >/dev/null 2>&1; then
        # Get loop device from first partition (all share same loop device)
        if [[ -z "$loop_device" ]]; then
          loop_device=$(findmnt -n -o SOURCE "$part_mount" || echo "")
          # Extract base loop device (e.g., /dev/loop0p1 â†’ /dev/loop0)
          loop_device="${loop_device%p*}"
        fi

        if umount "$part_mount" 2>/dev/null; then
          echo "  Unmounted $part_mount" >&2
        else
          echo "  Warning: Failed to unmount $part_mount" >&2
        fi
      fi

      # Remove partition mount point
      rmdir "$part_mount" 2>/dev/null || true
    done
  else
    # Single-partition mount
    if findmnt "$mount_point" >/dev/null 2>&1; then
      # Get loop device before unmounting
      loop_device=$(findmnt -n -o SOURCE "$mount_point" || echo "")

      # Unmount
      if umount "$mount_point" 2>/dev/null; then
        echo "Unmounted $mount_point"
      else
        echo "Warning: Failed to unmount $mount_point" >&2
      fi
    else
      echo "Not mounted: $mount_point"
    fi
  fi

  # Stop any RAID arrays that were mounted under this mount point
  stop_raid_arrays "$mount_point"

  # Detach loop device if found
  if [[ -n "$loop_device" ]] && [[ "$loop_device" =~ ^/dev/loop ]]; then
    if losetup -d "$loop_device" 2>/dev/null; then
      echo "Detached loop device $loop_device"
    else
      echo "Warning: Failed to detach $loop_device" >&2
    fi
  fi

  # Remove base mount point
  rmdir "$mount_point" 2>/dev/null || true

  exit 0
}

# Status command
do_status() {
  local medium_hash="$1"

  validate_hash "$medium_hash"

  local mount_point="/mnt/ntt/$medium_hash"

  if findmnt "$mount_point" >/dev/null 2>&1; then
    echo "Mounted at $mount_point"
    exit 0
  else
    echo "Not mounted: $mount_point"
    exit 1
  fi
}

# Main dispatch
[[ $# -ge 1 ]] || usage

case "$1" in
  mount)
    [[ $# -eq 3 ]] || usage
    do_mount "$2" "$3"
    ;;
  unmount)
    [[ $# -eq 2 ]] || usage
    do_unmount "$2"
    ;;
  status)
    [[ $# -eq 2 ]] || usage
    do_status "$2"
    ;;
  *)
    usage
    ;;
esac
